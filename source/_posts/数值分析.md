---

title: 数值分析
declare: true
date: 2021-09-29 10:21:02
tags: [数值分析]
categories: [数学]
toc: true
---


<meta name="referrer" content="no-referrer" />  

<!--more-->

# 数值分析 (Numerical Analysis)

[TOC]

## Part 0 绪论

在此感谢华中科技大学覃婷婷老师在B站上上传的公开课。[相关网站](https://www.bilibili.com/video/BV1sh41127RZ?p=1)

感谢北京交通大学的王老师的公开课。[相关网站](https://www.bilibili.com/video/BV1mE411i749?from=search&seid=17744663425317452137&spm_id_from=333.337.0.0)

什么是数值分析？数值分析有什么用？数值分析是利用计算机技术对复杂函数求出近似解的一门计算科学。**是学习和了解科学计算的桥梁**。

数学分析如何学习（要求）？

1. 注意掌握方法的原理
2. 注意掌握方法的构造方法
3. 重视方法的误差分析
4. 做题（串联知识点，强化思考）★
5. 注意与实际相结合
6. **完成并掌握**有关算法与程序的开发

在高等数学中，我们可以使用Taylor公式对一些函数进行高阶多项式逼近。这其实就是一种数值分析。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0929/073721_e1660245_5550632.png "屏幕截图.png")

然而，纯粹的人工计算和使用计算机计算之间存在着一个区别。**计算机的小数存在舍入误差**，如 3.1415926....这个数字，计算机是不可能进行准确存储的。即存在**误差**。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1006/093629_8ef8a00b_5550632.png "屏幕截图.png")

## Part 1 误差

### 1.1 误差的定义与来源分类

$\color {red}{误差}$:一个物理量的真实值与计算值之间的差异

###### 误差的来源

1. 模型误差(Modeling Error)：实际问题中抽象出数学模型时的误差
2. 观测误差(Measurement Error)：测量模型参数时得到的误差
3. 方法误差/截断误差(Truncation Error): 求近似解
4. 舍入误差(Roundoff Error):计算机字长有限

舍入误差是怎么出现的呢？这一块的分析需要了解计算机表示实数的方式，以及计算机计算的基本原理。计算机是这样表示实数的：
$$
x=±\beta^c×0.a_1a_2...a_t\\
其中,\beta代表进制,c为阶码,L<=c<=U(L,U为固定整数),t为字长
$$
那么机器数系可表示为:
$$
f(\beta,t,L,U)=\{±\beta^c×0.a_1a_2...a_t|a_i∈\{0,1,..,\beta-1\},L≤c≤U\}
$$
这也就意味着机器数系不像是实数系是稠密的，连续的。机器数系是**离散的，有限的**

如果t=2，那么0.123这个数在计算机内是不能准确存储的。对于用户输入的数字，在计算机中会存在三种情况:

1. $x∈f(\beta,t,L,U):照常接受$

2. $x\notin f(\beta,t,L,U):但m<=|x|<=M,四舍五入$

3. $x>M\;or\;x<m:数值上溢或下溢$

计算机本质上只会做**加减乘除**这四则运算。我们先看看加减法是如何进行计算的：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1006/101819_947bd03e_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1006/102000_6a0b2142_5550632.png "屏幕截图.png")

在加法对阶时，数值0.002337已经超出了我们的数系F，但是由于累加器的存在，这个数字的字长其实是合法的。

### 1.2 传播与累积 (Spread & Accumulation)

在迭代算法中，误差会随着计算而累积，放大。大家最熟知的例子就是蝴蝶效应。接下来我们将通过一个例子来看一看。误差是如何传播并被放大的，并探寻解决方式。
$$
I_n= \frac{1}{e}\int_0^1x^ne^xdx,n=0,1,2,..
$$

$$
I_0=\frac{1}{e}e^x|_0^1=1-\frac{1}{e}≈0.63212056\\
I_n=\frac{1}{e}\int_0^1x^nd_{e^x}=\\
\frac{1}{e}x^ne^x|_0^1-\frac{1}{e}n\int_0^1x^{n-1}e^xdx=\\
1-nI_{n-1}\\
迭代式:I_n=1-nI_{n-1}
$$

由于这个迭代式是从数学上推导出的精确解，所以本例中不存在方法误差。那么我们代入计算机，来计算一下吧:

![输入图片说明](https://images.gitee.com/uploads/images/2021/0929/081443_8e35342d_5550632.png "屏幕截图.png")

观察递推式，可知函数的结果是单调递减的，我用Python近似计算的结果也是单调递减的。没毛病，但这不是我想要的结果😂。

其实我想要的结果是这样的：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0929/081725_aec9c010_5550632.png "屏幕截图.png")

然后我又试了一下，明白了为什么没有出现PPT上的结果了，其结果是因为，Python对浮点数运算进行了优化，电脑使用的浮点数精度较高，导致误差传播的很小。运行下面的代码，你就会瞬间得到“正确的”错误答案：

```python
def hw_04(n):
    #a_prev = 1 - (1 / math.e) ##替换成这个答案是正常的
    a_prev = 0.63212059 #强制进行人工的四舍五入减少精度
    result = 0
    print("i=0:",a_prev)
    for i in range(1,n+1):
        a_i = 1-i*a_prev
        a_prev = a_i
        result = a_i
        print("i=%d:"%i,a_i)
    return result
```

```
i=0: 0.63212059
i=1: 0.36787941
i=2: 0.26424117999999996
i=3: 0.2072764600000001
i=4: 0.17089415999999957
i=5: 0.14552920000000213
i=6: 0.1268247999999872
i=7: 0.11222640000008965
i=8: 0.10218879999928276
i=9: 0.08030080000645512
i=10: 0.1969919999354488
i=11: -1.1669119992899368
i=12: 15.002943991479242
i=13: -194.03827188923015
i=14: 2717.535806449222
i=15: -40762.03709673833

```

接下来，我们来计算一下误差
$$
记第n项误差为|E_n|,第n项真实值为I_n,估计值为I^*_n\\
|E_0|=|I_0-I_0^*|=0.5*10^{-8}在第9位进行四舍五入\\
|E_n| = |I_n-I_n^*|=|1-nI_{n-1}-(1-nI_{n-1}^*)|=|n(I^*_{n-1}-I_{n-1})|=n|E_{n-1}|\\
|E_n| = n!|E_0|
$$
如果进行四舍五入，降低计算精度，我们的误差是n的阶乘这个量级的。那么减少误差的方式就有两种：**1. 改变计算方式(换算法)，2.让初始精度足够高，如同我第一次计算时那样**

方法二，暂且不表。我们想想其它的方式来计算这个式子。

之前的迭代是从低向高计算，我们这次反其道而行之。还是原来的迭代式将其移项整理得：
$$
I_{n-1}=\frac{1}{n}(1-I_n)
$$
我们这次计算，只需要提供一个I~N~然后从高向低进行迭代。那么I~N~如何估计呢？
$$
I_{N}=\frac{1}{e}\int_0^1x^Ne^xdx\\
\frac{1}{e}\int_0^1x^Ndx<I_N<\int_0^1x^Ndx\\
\frac{1}{e(N+1)}<I_N<\frac{1}{N}\\
I_N^*=\frac{1}{2}[\frac{1}{e(N+1)}+\frac{1}{N}]≈I_N\\
|E_N| = |I_N^*-I_N|\\
N->\infty,|E_N|->0
$$
 取：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0929/084818_46efe52f_5550632.png "屏幕截图.png")

得：

```python
def hw_05(number,item_term):
    a_n = number
    print("i:%d ="%item_term,a_n)
    for i in range(item_term-1,0,-1):
        a_prev = (1-a_n)/i
        print("i:%d =" % i, a_prev)
        a_n = a_prev

hw_05(0.042746233,15)
```

```
i:15 = 0.042746233
i:14 = 0.06837526907142857
i:13 = 0.07166344084065934
i:12 = 0.07736137992994506
i:11 = 0.0838762381881868
i:10 = 0.09161237618118132
i:9 = 0.10093195820209096
i:8 = 0.11238350522473863
i:7 = 0.12680235639646592
i:6 = 0.145532940600589
i:5 = 0.17089341187988222
i:4 = 0.20727664703002946
i:3 = 0.26424111765665687
i:2 = 0.3678794411716716
i:1 = 0.6321205588283284
```

计算反向计算的误差为:

![输入图片说明](https://images.gitee.com/uploads/images/2021/0929/090249_03ad75ae_5550632.png "屏幕截图.png")

这比之前n！的量级好太多了。**这样误差递减的算法叫做稳定的算法**。

### 1.3 误差与有效数字 (Error & Significant number)

###### 绝对误差 absolute error

$$
e^*=x^*-x\;,其中x为精确值，x^*为近似值
$$

然而，很多时候我们并不知道精确值（知道精确值了干嘛还要近似呢？）

那么为了描述一个结果是否精确，我们引入新的概念**绝对误差限 (accuracy)**【近似程度】。$|e^*|$的上限记为$\epsilon^*$我们称$\epsilon^*$为绝对误差限，工程上常记为$x=x^*±\epsilon^*$.

![输入图片说明](https://images.gitee.com/uploads/images/2021/0929/091143_b1cf7a6e_5550632.png "屏幕截图.png")

和超市里的一袋面粉，1500g±5g是一个道理。



###### 相对误差 relative error

5吨±1吨，5微克±1微克，这两种精度给人的感觉就不同，为了更准确的在**量级层面**上比较精度，我们引出相对误差的概念：
$$
e_r^*=\frac{e^*}{x}=\frac{x^*-x}{x}=\frac{x^*-x}{x^*}
$$
用绝对误差比上精确值(可信的估计值),**相对误差的绝对值越小，近似程度越高。**

对应的**相对误差限(relative accuracy)**,的定义为: 绝对误差限比上近似值。
$$
|\epsilon_r^*|=\frac{\epsilon^*}{|x^*|}
$$

20cm±1cm：我们可以得到其相对误差精度$\frac{1}{20}=0.5$

###### 数值的计算误差

![输入图片说明](https://images.gitee.com/uploads/images/2021/1007/103028_1956a98d_5550632.png "屏幕截图.png")

其中，微分的概念是两个相邻数的差，那么我们将其引入至数值分析当中可得出以下结论:
$$
e(x^*)=x^*-x=d_x\\
e_r(x^*)=\frac{x^*-x}{x}=\frac{d_x}{x}=d_{lnx}
$$
举个例子:

请求出$y=x^n$,中函数的相对误差与自变量的相对误差之间的关系:
$$
y=x^n\\
lny=n\;lnx\\
d_{lny}=nd_{lnx}\\
e_r(({x^*})^{n})=ne_r(x^*)
$$
所以可得出结论，如果自变量存在误差，那么对应函数值的误差将扩大n倍

###### 有效数字 significant digit

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/074502_fdfacd2a_5550632.png "屏幕截图.png")

举个例子:

$\pi=3.14159265....$,我们对小数点后第5位做四舍五入(数字9)得$\pi^*=3.1416$.从右向左数，直到第$\pi^*$的第一个非零数字。所以该例中有效数字为5.在小数点后第6位做四舍五入(数字2)$\pi^*=3.14159$,有效数字为6

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/075625_3ee22920_5550632.png "屏幕截图.png")

科学计数法的严格定义：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/080110_0630a923_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/080225_9077fce1_5550632.png "屏幕截图.png")
$$
\pi^*=\frac{355}{113}=\color{red}{0.3141592}\color{black}{9203...}*10^1\\
\pi=\color{red}{0.3141592}\color{black}{6535...}*10^1\\
|\pi^*-\pi| < 0.27*10^{-6}<0.5*10^{1-7}\\
n=7,m=1\\
∴近似值有7位有效数字。\\
相对误差限|\epsilon_r^*|=|\frac{\pi-\pi^*}{\pi}|<9*10^{-8}
$$

**有效数字与相对误差限的关系**
$$
已知近似数x^n有5位有效数字,求其相对误差限\\
∵x^n有5位有效数字\\
得\;x^*=±0.a_1a_2...a_5×10^m,a_1>=1\\
n=5\\
|x^*-x|≤0.5×10^{m-5}\\
相对误差\frac{|x^*-x|}{x^*}≤\frac{0.5×10^{m-5}}{0.a_1a_2...a_5×10^m}≤\\\frac{5×10^{-5}}{a_1}≤\frac{1}{2a_1}×10^{-4}<\frac{1}{2}×10^{-4}\\
x的相对误差限为0.5×10^{-4}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1008/090231_607a5959_5550632.png "屏幕截图.png")

**例题**

![输入图片说明](https://images.gitee.com/uploads/images/2021/1008/090817_e4373eb8_5550632.png "屏幕截图.png")

$$
\sqrt[3]{8}<\sqrt[3]{23}<\sqrt[3]{27}\\
\sqrt[3]{23}=0.2a_2...×10^1\\
\frac{|x^*-x|}{|x^*|}\leqslant\frac{1}{2*2}×10^{1-n}<0.1\% \\
0.25×10^{1-n}<0.01×10^{-1}\\
1-n\leqslant-3\\
x^*最少取4位有效数字
$$


### 1.4 良态问题和病态问题

###### 病态问题

由于初始数据的微小变化，导致计算结果出现剧烈变化的问题，称之为病态问题。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1008/095356_eda05fd9_5550632.png "屏幕截图.png")

###### 良态问题

由于初始数据的微小变化，计算结果出现微小变化的问题。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1008/100051_7e4ce448_5550632.png "屏幕截图.png")

### 1.5 函数的误差估计 Error estimation for function

对于函数$A=f(x),若x^*代替x,A的影响如何?$
$$
分析:\\
e^*(A) = f(x^*)-f(x)=f^{'}(\xi)(x^*-x)\\
e^*(x)=x^*-x\\
x->x^*,f^{'}(\xi)≈f^{'}(x^*)\\
|e^*(A)|≈|f^{'}(x^*)|*|e^*(x)|\\
称|f^{'}(x^*)为放大因子或绝对条件数
$$
绝对误差求完了，接着来推导函数的相对误差估计：
$$
|e_r^*(x)|=|\frac{e^*(x)}{x^*}|\\
|e_r^*(A)|=|\frac{e^*(A)}{f(x^*)}|=|\frac{f(x^*)-f(x)x^*(x^*-x)}{(x^*-x)f(x^*)x^*}|
\\≈|\frac{x^*f^{'}(x^*)}{f(x^*)}||e_r(x^*)|
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/084635_1b45138b_5550632.png "屏幕截图.png")
$$
解:设截取n位有效数字后得x^*≈x,则:\\|e_r^*(y)|≈|\frac{x^*y^{'}(x^*)}{y(x^*)}||e_r(x^*)|\\
=\frac{|e_r(x^*)|}{ln(x^*)}=\frac{|x-x^*|}{x^*ln(x^*)}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/085633_42e19ce3_5550632.png "屏幕截图.png")

###### 编程技巧

1. 避免相近两数相减

   ![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/085939_076a75cb_5550632.png "屏幕截图.png")

2. 避免小分母

3. 避免大数与小数的二元运算

4. 避免先化简再计算，减少步骤，减小误差

5. 选用数值稳定的算法

<br>

## Part 2 插值 (Interpolation)

### 2.1 问题的提出

与机器学习中的回归问题一样，对于某个函数f(x)我们只知道它的几个离散点，但是我想估计出在其定义域上任意值的函数值，和解？

因此我们的需求诞生了，**我们希望根据给定的数据点(函数表)做出一个能反映函数f(x)特性，又能方便计算的简单函数p(x),使得p(x)≈f(x)**.

或者建一个神经网络来近似函数。

![](https://images.gitee.com/uploads/images/2020/0516/113807_2fbfce19_5550632.png)

数学上，就是一个典型的函数逼近问题,下图中也是类似的例子。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/092048_36fb4aa1_5550632.png "屏幕截图.png")

通常，我们使用多项式函数为近似函数p(x),且
$$
p(x_i)=f(x_i)\;i=0,1,...,n\\
满足上面插值点的函数，就是我们期望的插值函数
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/092340_41185aab_5550632.png "屏幕截图.png")

常用的插值方法**(假设函数备选设计方案)**:

1. 多项式插值:P(x)为多项式
2. 分段插值：P(x)为分段多项式函数
3. 三角插值：P(x)为三角函数
4. ... ...

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/093036_d7e29653_5550632.png "屏幕截图.png")

按照机器学习的概念来讲(最小二乘还是插值暂且不论):
$$
x^{(i)}为特征向量，y^{(i)}为标签值,i=1,...m.\\
寻找假设函数h_{\theta}(x)=\theta^T x+b
\\使得h_{\theta}(x^{(i)})=y^{(i)}
$$
其中，$P(x)=a_0+a_1x+a_2x^2+...+a_nx^n=\sum_{k=0}^na_kx^k$

那么插值的问题存在如下三点：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/093657_c8e644c0_5550632.png "屏幕截图.png")

把插值节点代入插值多项式得：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/094844_6d46b58c_5550632.png "屏幕截图.png")

其中$x_i,y_i$已知，那么问题就转化为了，**线性方程组是否具有唯一解问题。**，那么我们只需要**计算一下系数行列式，如果它不为0，那么方程有解**。也就意味着插值多项式唯一。

系数行列式为:

![输入图片说明](https://images.gitee.com/uploads/images/2021/0930/095114_6718509f_5550632.png "屏幕截图.png")

那么我们就能导出**插值多项式的唯一性定理**：
$$
满足P(x_i)=y_i,i=0,..,n\;\\其中插值点均为互斥点\\
次数不超过n的插值多项式是唯一存在的
$$

如果插值多项式唯一，我们如何构造它？

第一种最好想的方法就是应用唯一性定理，构造次数不超过n的高阶多项式。(待定系数法)

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/081625_0b919f77_5550632.png "屏幕截图.png")

### 2.2 拉格朗日(Lagrange)插值

刚才的待定系数法在节较少时还是可以算的，假设现在有100万个互斥的插值节点，请问如何手算线性表达系数？

所以我们要寻找新的插值多项式构造方法来减少计算量。下面介绍拉格朗日多项式(Lagrange Polynomial)：

之前我们待定系数，这次假设所有的系数都是插值节点的函数值，**那我们就不用求系数了，转而求函数 (核心思路)**
$$
求n次多项式:\\
L_n(x)=y_0l_0(x)+y_1l_1(x)+...+y_nl_n(x)\\
其中y_i已知,且L_n(x_i)=y_i,u=0,1,2,...,n
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/083701_9e867dd9_5550632.png "屏幕截图.png")

以上图为例，我们只需要找出两个**一阶基函数**，就可以确定该拉格朗日多项式。

观察上述**拉格朗日基函数**，我们能看到一些好玩的现象：
$$
l_0(x)=\frac{x-x_1}{x_0-x_1}y_0\\
x=x_0,l_0(x_0)=\frac{x_0-x_1}{x_0-x_1}y_0=y_0\\
x=x_1,l_0(x_1)=\frac{x_1-x_1}{x_0-x_1}y_0=0\\
l_j(x_i)=1,i=j\\
l_j(x_i)=0,i\;!=j
$$
其本质是，由于我们假设插值节点为待定的系数，那么:
$$
L_j(x)=\sum_{i=0}^jl_j(x)y_i\\
当x=x_k时,只有l_k(x_k)=1,其它全为0时，插值点能满足插值函数条件。即:\\
L_n(x_k)=l_k(x_k)y_k+\sum_{j=0,j≠k}^nl_j(x_j)y_j=l_k(x_k)y_k=y_k\\
l_i(x_k)=\delta_{ik}=
\begin{cases}1\;\;(i=k)
\\0\;\;(i≠k)
\end{cases}
$$
如何求**拉格朗日基函数** ?首先明确的是: $l_i(x)均为n阶多项式,i只是下标与插值节点x_j存在关系$


$$
我们希望找到l_i(x),i=0,...n。使得l_i(x_j)满足下列条件:\\
l_i(x_j)=1,i=j\\
l_i(x_j)=0,i\;!=j\\
显然对于l_i而言存在n个零点:\\
l_i(x)=C_i(x-x_0)..(x-x_n)=\prod_{j≠i,j=0}^n(x-x_j)\\
l_i(x_i)=1\;\;=>C_i=\prod_{j≠i}\frac{1}{x_i-x_j}\\
l_i(x)=\prod_{j≠i,j=0}^n\frac{x-x_j}{x_i-x_j}
$$


![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/090915_b64c8645_5550632.png "屏幕截图.png")

所以得出以下形式:
$$
L_n(x)=\sum_{i=1}^ny_i\prod_{k=0,k≠i}^n\frac{x-x_i}{x_i-x_k}
$$
我们称$L_n(x)$为Lagrange插值多项式，$\prod_{k=0,k≠i}^n\frac{x-x_i}{x_i-x_k}$为Lagrange插值基函数。

所以拉格朗日插值多项式**仅与插值节点x有关与函数值y无关**。

看之前的推导很迷糊，实际用起来是非常简单的：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/100059_d8468a8d_5550632.png "屏幕截图.png")

分子:除插值节点i外 ，让插值点x和剩下的插值节点做差连乘

分母:插值节点i 和其它所有插值节点做差连乘(除了它自己)

###### 插值余项 (误差)

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/101120_3e107311_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/101952_a3cbaaa3_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/103354_ae94cb73_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1002/101014_71b79c17_5550632.png "屏幕截图.png")

首先看1次Lagrange插值，1次，即选择两个插值结点，45°<=50°<=60°，所以我选择如下两个插值节点:
$$
x_0=\frac{\pi}{6}\;x_1=\frac{\pi}{4}\;x_2=\frac{\pi}{3}\\
1次拉格朗日插值为:\\
L_1(x)=\frac{x-\frac{\pi}{3}}{\frac{\pi}{4}-\frac{\pi}{3}}*\frac{\sqrt{2}}{2}+\frac{x-\frac{\pi}{4}}{\frac{\pi}{3}-\frac{\pi}{4}}*\frac{\sqrt3}{2}\\
x=50°:L_1(x)=0.7600796553858445\\
$$
此时我们使用的是$x_1,x_2$插值节点，我们的插值点位于插值节点内，属于**内插(interpolation)**。接着计算误差:
$$
R_1(x)=\frac{f^{''}(\xi_x)}{2!}(x-x_1)(x-x_2)\\
0.00538<R_1(x)<0.00660
$$
反之，我们如果在插值点外选择插值节点，称之为**外推(extrapolation)**

![输入图片说明](https://images.gitee.com/uploads/images/2021/1002/134640_ba5c97fa_5550632.png "屏幕截图.png")

然后我们使用三点2次来进行插值可得:

![输入图片说明](https://images.gitee.com/uploads/images/2021/1002/134754_bcc9da34_5550632.png "屏幕截图.png")

由此可见插值时次数越高，结果越精准，但是需要根据具体情况具体选择插值多项式的次数(如同调参)。

那么对任意具有n+1阶的函数f(x)都存在:
$$
L_n(x)=\sum_{i=1}^ny_i\prod_{k=0,k≠i}^n\frac{x-x_k}{x_i-x_k}\\
f(x)=\sum_{i=1}^nf(x_i)L_{in}(x)+\frac{f^{n+1}(\xi)}{(n+1)!}\omega_{n+1}(x)\;\;x\in[a,b]\\
\omega_{n+1}(x)=\prod_{i=0}^n(x-x_i)
$$


### 2.3 差商与牛顿(Newton)插值

拉格朗日插值法，它本身存在一个小问题。如果现在我有n+1个插值节点，那么我们会有n+1个不超过n次的拉格朗日插值多项式。但现在**如果新增或删除一个插值节点**，所有插值多项式都需要重新计算。那么有没有一种多项式，**可以在不改变原来的计算结果上新增一个新的项的插值方式呢？**。这就是接下来要介绍的牛顿插值。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1002/135352_6f3e8516_5550632.png "屏幕截图.png")

牛顿插值思想如下:

![输入图片说明](https://images.gitee.com/uploads/images/2021/1002/135443_b38ea18f_5550632.png "屏幕截图.png")

从一点0次插值多项式递推，已知推到n+1次n+2点多项式。

#### 0x01 差商 (divided difference)

$$
f[x_i,x_j]=\frac{f(x_i)-f(x_j)}{x_i-x_j}\;(i≠j,x_i≠x_j)
$$

如果对分母取极限，一阶差商就变成了一阶导数的定义。二阶差商也可如下进行递归定义:
$$
f[x_i,x_j,x_k]=\frac{f[x_i,x_j]-f[x_j,x_k]}{x_i-x_k}
$$
所以n阶差商至少需要n+1个节点才能定义。那么k阶差商如何计算呢？
$$
f[x_0,...,x_k]=\sum_{j=0}^k\frac{f(x_j)}{(x_j-x_0)..(x_j-x_{j-1})(x_j-x_{j+1})..(x_j-x_k)}
$$
差商是$f(x_i)$函数的线性组合

n阶差商和n阶导数之间的关系如下：
$$
f(x)在[a,b]上有n阶导数\\
f[x_0,...,x_k]=\frac{f^{n}(\xi)}{n!}\;\xi∈[a,b]
$$
我们把1阶差商到n阶差商打出一张表：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1003/081125_e0e897ac_5550632.png "屏幕截图.png")

设差商表为一个二维数组dp,那么我们可以得到如下规律:
$$
初始条件为:第一列与第二列。\\
设数组dp[n+1][n+1]\;,行下标为\;i,列下标为\;j(j阶)\\
dp[i][0]=x_i,dp[i][1]=f(x_i)\;i∈[0,n]\\
根据动态规划定义,得状态转移方程为:\\
(j>i)\;dp[i][j]=\frac{dp[i][j-1]-dp[i-1][j-1]}{dp[i][0]-dp[i-(j-1)][0]}\;j=2,....n,i=1,...,n\\
(j<=i)\;dp[i][j]=0\\
$$


#### 0x02 牛顿插值

![输入图片说明](https://images.gitee.com/uploads/images/2021/1003/084123_7e91f971_5550632.png "屏幕截图.png")

$其中:c_0,零阶差商,c_1,一阶差商,...$

###### 插值余项

![输入图片说明](https://images.gitee.com/uploads/images/2021/1003/085621_1ef7ae06_5550632.png "屏幕截图.png")

根据余项，我们也可以推出n阶差商和n阶微分有如下关系：
$$
f[x_0,x_1,...,x_n,x]=\frac{f^{(n+1)}(\epsilon)}{(n+1)!}
$$
**例题**

![输入图片说明](https://images.gitee.com/uploads/images/2021/1003/085841_7816a0eb_5550632.png "屏幕截图.png")

本质上就是打表计算，如下:

![输入图片说明](https://images.gitee.com/uploads/images/2021/1003/090335_f2e5a7df_5550632.png "屏幕截图.png")

### 2.4 差分与等距节点的Newton插值

在之前说过，我们用计算机计算最好少用小数间的除法运算，差商可以用，但是对于计算机而言是不精确的。我们为了**减少插值时除法的应用**，接下来介绍差分与等距节点的Newton插值。

$$
当节点间等距分布时:x_i=x+ih\;(i=0,..,n)
$$

![输入图片说明](https://images.gitee.com/uploads/images/2021/1003/091425_e20e90e2_5550632.png "屏幕截图.png")

编程时，底下的性质随便用:

![](https://images.gitee.com/uploads/images/2021/1003/091629_54c266fa_5550632.png)

差分表和插值公式如下：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1004/081154_e21a4a4f_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1004/081024_aede4dbd_5550632.png "屏幕截图.png")



### 2.5 埃尔米特(Hermite)插值

**既要求函数点重合也要求导数点重合的插值是Hermite插值**。
$$
插值函数g(x_i)满足:\;g(x_i)=f(x_i),g^{'}(x_i)=f^{'}(x_i),..,g^{(m)}(x_i)=f^{(m)}(x_i)
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1004/083132_d08213b3_5550632.png "屏幕截图.png")

###### 待定系数法

![输入图片说明](https://images.gitee.com/uploads/images/2021/1004/083743_26cccf31_5550632.png "屏幕截图.png")

###### 牛顿插值法

接下来介绍重节点差商，以便于应用Hermite插值：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1004/084406_3aa9adf6_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1004/085023_4383b88b_5550632.png "屏幕截图.png")

###### 拉格朗日插值法

一个两点三次的Hermite插值多项式，还能怎么求呢？

![输入图片说明](https://images.gitee.com/uploads/images/2021/1005/082638_9a4acce3_5550632.png "屏幕截图.png")

可以使用待定系数法。根据上表我们可以构造出如下的Hermite插值多项式：
$$
H_3(x)=\alpha_0(x)y_0+\alpha_1(x)y_1+\beta_0(x)m_0+\beta_1(m_1)\\
\alpha表征函数信息,\beta表征导数信息
$$
且有如下的约束条件：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1005/083011_cc9ae185_5550632.png "屏幕截图.png")

那么，我们就可以构造具体的多项式结构了:
$$
\alpha_i(x)=(a_ix+b)l^2_i(x)\\
\beta_i(x)=c_i(x-x_i)l_i^2(x)
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1005/083303_dc898803_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1006/081654_3e89e3b0_5550632.png "屏幕截图.png")

### 2.6 分段低次插值

多项式次数越高，图像越震荡，在某些问题上反而精度会降低，为了减少此现象对插值误差的影响，我们引入**分段低次插值**的概念。

###### 分段线性插值

![输入图片说明](https://images.gitee.com/uploads/images/2021/1005/090057_4c8f520b_5550632.png "屏幕截图.png")

上图中，**黑色**曲线是f(x)，其它颜色的线都是不同次数的Lagrange插值。当阶数很高时，在端点处的误差会很大（Runge现象）。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1005/090901_e33d470e_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1005/091539_df15fc0b_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1006/082018_ce6375ec_5550632.png "屏幕截图.png")

###### 分段三次Hermite插值

![输入图片说明](https://images.gitee.com/uploads/images/2021/1006/082909_d05f4b50_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1006/083202_6e7a1881_5550632.png "屏幕截图.png")

### 2.7 三次样条(spline) 插值

<br>

## Part 3 函数逼近与曲线拟合

<br>

## Part 4 数值微积分

<br>

## Part 5 微分方程数值解

<br>

## Part 6 线性方程组求解

本章是为解决大型超大型线性方程组在计算机上求解的常用数值方法的构造与原理。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1021/085230_0f7cf6c2_5550632.png "屏幕截图.png")

实际中出现的情况最多的是m=n的情况，且假设有唯一解。

解法有两大类：**直接法**和**迭代法**

直接法：有限次就计算出近似解的方法

迭代法：通过猜测初始结果然后逐步迭代计算来满足精度要求

### 6.1 线性方程组的迭代解法

**基本思想**

类比简单迭代法（第七章）：
$$
Ax=b\\
Ax-b=0\\
等价变形为:
x=Bx+g\\
向量的迭代格式为:
\\x^{(k+1)}=Bx^{(k)}+g\\
x^{(1)},x^{(2)},x^{(3)}...就是各个解
$$

#### 6.1.1 Jacobi 迭代法

单看方程组中的单个方程，把第i个变元用其余n-1个变元表出的到如下这样一个**不动点方程组**。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1021/090716_5ce8e67a_5550632.png "屏幕截图.png")

接着写出其迭代格式：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1021/090940_08131663_5550632.png "屏幕截图.png")



#### 6.1.2 Seidel 迭代法

在Jacobi的基础之上，我们稍微改一改就变成Seidel迭代法了。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1021/091937_767647d3_5550632.png "屏幕截图.png")

之前Jacobi迭代没用上上一步的迭代结果而是直接使用初值，但Seidel迭代法在第n个不动点方程计算的时候会参考前n-1个不动点方程计算出的结果。

但是，Seidel迭代不能取代Jacobi迭代法。因为这两种迭代法的收敛范围不同，在取交集的时候Seidel比Jacobi更快。

#### 6.1.3 Sor法 (超松弛法)

![输入图片说明](https://images.gitee.com/uploads/images/2021/1021/093256_20906add_5550632.png "屏幕截图.png")



此时引入线性代数相关知识，将迭代法的方程组写法改写为矩阵形式。我们做出如下假设：
$$
Ax=b\\
A=D-L-U\;设D^{-1}存在
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1023/164929_8fce32e7_5550632.png "屏幕截图.png")
$$
Ax=b<=>\\x=D^{-1}(L+U)x+D^{-1}b
$$
可得Jacobi迭代法的矩阵形式：
$$
x^{(k+1)}=D^{-1}(L+U)x^{(k)}+D^{-1}b\\
令B_j==D^{-1}(L+U),g=D^{-1}b\\
x^{(k+1)}=B_jx^{(k)}+g
$$
那么对于这个不动点方程计算出的不动点向量，如何判断其是否收敛呢？

#### 6.1.4 范数与谱半径

我们通过定义范数的形式来度量向量的敛散性。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1023/173041_d9f41e96_5550632.png "屏幕截图.png")


$$
lim_{k->\inf}||x^{(k)}-x^*||=0
$$


同时，如果形为$Ax$的矩阵和向量乘法，此时我们应当如何计算其范数呢？引入定义**算子范数**，定义如下：
$$
A\in\;R^{n×n}
\\||A||=max_{x\in R^{n}\;x≠0}\frac{||Ax||_p}{||x||_p}
$$
定义谱半径：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1024/093118_5a436c9b_5550632.png "屏幕截图.png")

那么我们就找到了矩阵算子范数的下界：
$$
||Ax||≤||A||\;||x||\\
\rho(A)≤||A||
$$


##### 迭代法的收敛与误差分析

![输入图片说明](https://images.gitee.com/uploads/images/2021/1024/093933_250c2bfe_5550632.png "屏幕截图.png")

###### 判别条件 1 (充分条件)

![输入图片说明](https://images.gitee.com/uploads/images/2021/1024/095504_c864ff88_5550632.png "屏幕截图.png")

###### 判别条件 2 (充分条件)

在实际问题中，经常会有以下现象出现：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1024/095729_01cde52d_5550632.png "屏幕截图.png")

在系统中，当某一特征的重要性非常高，就会出现上面这个现象。

那么存在这样的一个事实：**严格对角占优阵是非奇异的，可逆的**

那么我们的第二种判别方法为：

**若矩阵A为严格对角占优阵，则$Ax=b$对于Jacobi和Seidel迭代对任意初始向量$x^{(0)}$都收敛**

证明：

<img src="https://images.gitee.com/uploads/images/2021/1025/093019_bab92761_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:50%;" />

###### 判别条件 3 (充分条件)

设A为对称正定矩阵，Ax=b的Seidel迭代对任意初始向量都收敛

###### 误差估计式

![输入图片说明](https://images.gitee.com/uploads/images/2021/1025/094853_cccad94a_5550632.png "屏幕截图.png")



### 6.2 线性方程组的直接解法

本章重点放在一般**公式的推导**上。注意学习与体会。其中Gauss消元法是直接法的基础。

#### 6.2.1 Guass 消元法

基本思想：把线性方程组通过消元的方法化为同解的上三角方程组,再从下向上依次求解（找到了ax=b这样形式的方程,解出来后再代入,递归此格式,求解完毕）【消元，回代】。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1026/095722_0f7adae8_5550632.png)

###### 消元过程

$$
\begin{cases}
a_{11}^{(0)}x_1+a_{12}^{(0)}x_2+...+a_{1n}^{(0)}x_n=b_1^{(0)}\\
a_{21}^{(0)}x_1+a_{22}^{(0)}x_2+...+a_{2n}^{(0)}x_n=b_2^{(0)}\\
...\\
a_{n1}^{(0)}x_1+a_{n2}^{(0)}x_2+...+a_{nn}^{(0)}x_n=b_n^{(0)}
\end{cases}
$$

消元过程像下图一样

![输入图片说明](https://images.gitee.com/uploads/images/2021/1026/101452_39da0f2d_5550632.png "屏幕截图.png")

保留第一行x~1~，把剩余n-1行x~1~前的系数消为0.

依次类推

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/090749_e14d2bc8_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/090836_b283e428_5550632.png "屏幕截图.png")

###### 回代过程

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/091818_0d104959_5550632.png "屏幕截图.png")

在接着下一个话题前，我们先看看Guass消元法的使用局限性：

1.**主元位置$x_{kk}$不能为0(m的分母)**。

2.有时Guass消元法的计算结果是错误的

问题1怎么办？

1. 通过初等行变换（换行），把主元换成非零数

2. 矩阵A的所有顺序主子式不为0

   顺序主子式：以主对角线为基准从$A_{11}$开始计算所有的行列式
   $$
   d_1=|a_{11}|\\
   d_2=
   \begin{vmatrix}a_{11}&a_{12}\\
   a_{21}&a_{22}\end{vmatrix}\\...
   $$
   

问题2是怎么回事？
$$
\begin{cases}
0.0001x_1+x_2=1\\
x_1+x_2=2
\end{cases}
$$
假设在**字长为4的计算机**上进行求解，计算机内部存储类似于：
$$
\begin{cases}
0.1000*10^{-3}x_1+0.1000*10^{1}x_2=0.1000*10^{1}\\
0.1000*10^{1}x_1+0.1000*10^{1}x_2=0.2000*10^{1}
\end{cases}
$$
开始模拟Guass消元法：
$$
m_{21}=-\frac{a_{21}}{a_{11}}=-10^{4}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1028/091520_e734e909_5550632.png "屏幕截图.png")

出现这种现象的原因是：作为分母的数太小了。影响计算精度

#### 6.2.2 LU 分解法

根据矩阵理论我们可以知道，方程组的消元过程可以通过**右乘行初等矩阵**的方式来实现，即Guass消元法可描述为：
$$
M_{n1}M_{n-1\;1}...M_{21}(A|b)=(A^{(1)}|b^{(1)})
$$
由于所有的M都是初等矩阵所以：
$$
M =M_{n1}M_{n-1\;1}...M_{21}=\begin{bmatrix}
1\\
m_{21}&1\\
m_{31}&m_{32}&1\\
...&...&...&...\\
m_{n1}&m_{n2}&...&m_{nn-1}&1
\end{bmatrix}
$$
其中上标代表第i次消元的结果，那么：
$$
A^{(n-1)}=MA\\
b^{(n-1)}=Mb\\
A^{(n-1)}为上三角矩阵,则:\\
令A^{(n-1)}=U\;M^{-1}=L
$$
那么系数矩阵可分解为：
$$
A = LU,其中原系数矩阵A行列式不为0
$$

$$
Ax=b\; <=>\\
LUx=b\\
\begin{cases}
y=Ux\\
Ly=b
\end{cases}
$$

如果L，U 已知，那么我们解上面这个方程组的计算量为：$2*\frac{n(n-1)}{2}$，比起Guass消元法的$\frac{n^3}{3}$少了不少。（但是加上分解的计算量其实它俩差不多）

那么问题来了，L，U这两个矩阵怎么算呢？

分解方式有：**Doolittle分解，Grout分解和LDU分解**

##### 0x01 Doolittle 分解

分解形式如下：

<img src="https://images.gitee.com/uploads/images/2021/1028/095203_3e564d88_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom: 67%;" />



首先对A的第一行和第一列进行分析：
$$
a_{1j} = (1,0,0,...,0)(u_{1j}\;;u_{2j}\;;...;u_{nj}) = u_{1j}\\
a_{i1}=(l_{i1},l_{i2},...,l_{in})(u_{11}\;;0\;;...;0)=l_{i1}u_{11}\\
得:
u_{1j}=a_{1j}\;\;;l_{i1}=a_{i1}/u_{11}
$$
其次对任意的a，我们都可以进行如下计算：
$$
a_{ij} = \sum_{k=1}^{j}=l_{ik}u_{kj}
$$
但是，观察矩阵可知：
$$
L:在i>j\;时才有非零值存在\\
U:在i≤j\;时有非零值存在
$$
那么，矩阵U的元素可表示为：
$$
i≤j:\\
a_{ij} = \sum_{k=1}^{i-1}l_{ik}u_{kj}+l_{ii}u_{ij}\;\;(l_{ii}=1)\\
u_{ij}=a_{ij}-\sum_{k=1}^{i-1}l_{ik}u_{kj}
$$
同理矩阵L的元素可表示为：
$$
i>j:\\
a_{ij} = \sum_{k=1}^{j-1}l_{ik}u_{kj}+l_{ij}u_{jj}\\
l_{ij}=\frac{a_{ij}-\sum_{k=1}^{i-1}l_{ik}u_{kj}}{u_{jj}}
$$
至此，Doolittle分解结束，矩阵L，U可分解为：
$$
L:l_{ij}=\frac{a_{ij}-\sum_{k=1}^{i-1}l_{ik}u_{kj}}{u_{jj}}\\
U:u_{ij}=a_{ij}-\sum_{k=1}^{i-1}l_{ik}u_{kj}
$$
在实际应用中，为节省内存空间，LU矩阵常常以下图方式存放：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1101/092433_fec0f21e_5550632.png "屏幕截图.png")

同时，不仅是为了节省内存，也是方便计算，以U为例：
$$
u_{ij}=a_{ij}-\sum_{k=1}^{i-1}l_{ik}u_{kj}\\
\color{red}{其中k为第k框}\\
以u_{33}为例:u_{33} = a_{33}-\sum_{k=1}^2l_{3k}u_{k3}
\\=a_{32} - (l_{31}u_{13}+l_{32}u_{23})
$$
画个小图图，一图胜千言，看看计算过程：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1101/094839_c6ca0203_5550632.png "屏幕截图.png")

对于L，同理：
$$
l_{32} = \frac{a_{32}-\sum_{k=1}^1l_{3k}u_{k2}}{u_{22}}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1101/095640_8ca72fde_5550632.png "屏幕截图.png")

算法相同，只是需要除一个数。

对下列矩阵进行LU分解：

<img src="https://images.gitee.com/uploads/images/2021/1101/102855_4cb023e9_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom: 80%;" />



##### 0x02 Grout 分解

分解形式如下：

<img src="https://images.gitee.com/uploads/images/2021/1028/095223_c95a28d9_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:67%;" />

##### 0x03 LDU 分解

分解形式如下：

<img src="https://images.gitee.com/uploads/images/2021/1028/095312_31a08bb1_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:67%;" />



#### 6.2.3 特殊线性方程组解法

##### 0x01 追赶法

此方法是用来解三对角方程组的，三对角方程组形式如下：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1102/092653_8b9a3624_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1102/092717_8389cd3a_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1102/092846_a89c4383_5550632.png "屏幕截图.png")

对上下带宽分别为p和q的n阶带状矩阵A有Doolittle分解，A=LU,则L为下带宽为q的单位下三角矩阵，U为上带宽p的上三角矩阵。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1102/093248_a4d7e7ed_5550632.png "屏幕截图.png")

那么接下来的问题就是求解**p,q,r**.

三个变量求出来了，LU分解也就做完了。就可以去求解线性方程组了。

根据矩阵乘法的规律不难推出：
$$
b_1=(1,0,...,0)(q_1;0;...;0)=q_1\\
c_1=(1,0,...,0)(r_1;q_2;...;0)=r_1\\
b_1=q_1\;\;,c_1=r_1\\
推a_i:\\
a_2=(p_2,1,...,0)(q_1;0;...;0)=p_2q_1\\
a_3=(0,p_3,1,0,...,0)(r_1;q_2;0;...;0)=p_3q_2\\
a_i=p_iq_{i-1}\;\;(i=1,...,n)\\
推b_i:\\
b_2=(p_2,1,...,.)(r_1;q_2;0...;0)=p_2r_1+q_2\\
...\\
b_i=p_ir_{i-1}+q_i\;\;(i=2,...,n)\\
推c_i:\\
c_1=r_1\\
c_2=(p_2,1,0,...,0)(0;r_2;0;...;0)=r_2\\
...\\
c_i=r_i\;\;(i=1,...,n-1)
$$
于是得到三对角矩阵的Doolittle分解公式为：
$$
q_1=b_1,r_k=c_k\;\;(k=1,...,n-1)\\
\begin{cases}
p_k=\frac{a_k}{q_{k-1}}\;\;(k=2,3,...,n)\\
q_k=b_k-p_kc_{k-1}\;\;(k=2,3,...,n)
\end{cases}
$$


### 6.3 线性方程组解对系数的敏感性

解对系数的敏感性指方程中由于系数的变化(扰动)导致所求解发生变化的情况。

如果线性方程组对系数很敏感，会导致求出的解失真。

通常称对系数敏感的方程组为**病态方程组**，反之为**良态方程组**。

如何用数学语言来描述，扰动这种现象呢？
$$
设方程组Ax=b的准确解为x^*\\
扰动后的方程组记作:(A+\delta A)x = b + \delta b\\
记扰动后的准确解为x^*+\delta x
$$
通过观察准确解和扰动解的相对误差限，可得出:
$$
Ax^*=b\;\;A(x^*+\delta x)=b+\delta b\\
考虑\delta A=0\\
相减有结果:A\delta x=\delta b\\
||\delta x||≤||A^{-1}||||\delta b||\\
由Ax^*=b得||x^*||≥\frac{||b||}{||A||}\\
\frac{||\delta x||}{||x^*||}≤||A||||A^{-1}||\frac{||\delta b||}{||b||}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1103/085740_e2138a7a_5550632.png "屏幕截图.png")

下面引出一个重要概念:
$$
对于非奇异矩阵A\\
称Cond_p(A)=||A||_p||A^{-1}||_p为矩阵A的条件数
$$
**条件数越大，解对系数越敏感,方程组越病态**





<br>

## Part 7 非线性方程与方程组求解 ※

方程是由等式连接起来的式子，非线性值自变量的次数不是1次的，最简单的一个非线性方程是$ax^2+bx+c=0$

或者说除了$f(x)=ax+b=0$，都是非线性方程。

我们这章就要研究针对这种方程和其方程组求解的问题。

### 7.1 引例

从实际问题中得到如下这样的一元方程，并想对其求解，这就是我们这一章主要要讲述的内容：
$$
f(\alpha)=(1-0.5tan\alpha)^{1.4}cos\alpha-0.32=0
$$
代数方程,形如:
$$
f(x)=a_0+a_1x_+a_2x^2+...+a_nx^n=0
$$
为n次**代数方程**。当底数或者指数不为整数时，我们称为**超越方程**

方程求根的本质是：**根的存在性，根的范围，根的精确化**

### 7.2 求解方法

非线性方程的求解法可以分成两类：**区间法和迭代法**。求根的过程就是构造一个数列{x~k~}。其中：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1011/091445_3125a68f_5550632.png "屏幕截图.png")

p为收敛阶，收敛阶越大，收敛速度越快，方法越好

### 7.3 二分法

理论基础：
$$
f(x)在[a,b]上连续,若:\\
f(a)f(b)<0,必存在f(\xi)=0\\
\xi等价于方程的根
$$
所以，我们的基本思想就是：

**把含根区间依次减半缩小，构造{x~k~}逼近x的近似值**

那么，根在哪个区间范围里呢？

![输入图片说明](https://images.gitee.com/uploads/images/2021/1011/092957_1de84da6_5550632.png "屏幕截图.png")

### 7.4 简单迭代法

因为二分法当快到收敛的时候计算的速度很慢，所以发明出了简单迭代法。

**基本思想**

对方程进行等价变换得到其等价的形式，然后用其等价式计算数列{x~k~}

**构造原理**
$$
对f(x)=0进行恒等变形,得:\\
x=g(x)\\
构造迭代公式:\\
x_{k+1}=g(x_k)
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1012/084304_67729348_5550632.png "屏幕截图.png")

数值分析和数学建模很像，我们都是**依据某种理论先构造方法，然后解释方法的合理性**。当$x=g(x)$时，我们称x为不动点，g(x)=x为不动点方程，其本质就是f(x)=0的根。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1012/091209_616d326b_5550632.png "屏幕截图.png")

#### 7.4.1 收敛判别的充分条件

![输入图片说明](https://images.gitee.com/uploads/images/2021/1012/093239_12f125a9_5550632.png "屏幕截图.png")

其中，条件2为**李普希思函数**，它的作用是约束函数的性质：**该函数必连续但不一定可导。介于连续和可导中间的这么一种状态**

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/084404_85418ee1_5550632.png "屏幕截图.png")

接着证明迭代的收敛性：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/085012_19672f6b_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/091631_fc0b228d_5550632.png "屏幕截图.png")

#### 7.4.2 局部收敛和全局收敛

局部收敛：收敛求根的初值需要靠近根，才能找到根（简单迭代法）

全局收敛：初值只要在区间内，就可以收敛（二分法）

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/093303_b4fa7483_5550632.png "屏幕截图.png")

#### 7.4.3 误差估计

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/100256_c1cb69ed_5550632.png "屏幕截图.png")

#### 7.4.4 迭代加速

##### 0x01 增量松弛法

还是觉得迭代法收敛慢，想加快收敛速度怎么办？

记增量为：
$$
\Delta x_k= x_{k+1}-x_k=\phi(x_k)-x_k
$$
那么为了加速收敛，我们可以：
$$
x_{k+1}=\phi(x_k)+C\Delta x_k\\
C=\frac{\phi^{'}(x_k)}{1-\phi^{'}(x_k)}
$$

##### 0x02 Aitken方法

如果迭代函数没有导数。我们怎么加速呢？

导数是函数的增量除以自变量增量的极限，那么我们必须**拥有两项函数值**。

矫正（迭代）2次，得：
$$
x_{k+1}^{(1)}=\phi(x_k)\\
x_{k+1}^{(2)}=\phi(x_{k+1}^{(1)})\\
x_{k+1}^{(1)}-x^*=\phi(x_k)-\phi(x^*)=\phi^{'}(\xi_1)(x_k-x^*)\\
x_{k+1}^{(2)}-x^*=\phi(x_{k+1}^{(1)})\phi(x^*)=\phi^{'}(\xi_2)(x_{k+1}^{(1)}-x^*)\\
$$
可推出：
$$
设\phi^{'}(\xi_1)≈\phi^{'}(\xi_2)≈L\\
x_{k+1}^{(1)}-x^*≈L(x_k-x^*)\\
x_{k+1}^{(2)}-x^*≈L(x_{k+1}^{(1)}-x^*)\\
x_{k+1}=x^*≈x_k-\frac{(x_{k+1}^{(1)}-x_k)^2}{x_{k+1}^{(2)}-2x_{k+1}^{(1)}+x_k}
$$

### 7.5 牛顿迭代法

牛顿迭代法又称**切线法**，是目前收敛速度最快的方法(至少平方收敛)。

#### 7.5.1 基本思想

把函数f(x)进行泰勒展开，只保留到线性部分。
$$
L(x)=f(x_k)+f^{'}(x_k)(x-x_k)\\
x_{k+1}=x_k-\frac{f(x_k)}{f^{'}(x_k)}
$$
上式称为Newton迭代公式。求根的方法叫做Newton迭代法（局部收敛）。因为是局部收敛的，所以实践中可以先用二分法减小区间然后再用Newton迭代法。

当然了，人们也整出来了一种特殊情况，在这种情况下Newton迭代法是全局收敛的**（充分条件）**。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/091941_994bb202_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/092704_d2137490_5550632.png "屏幕截图.png")

#### 7.5.2 几何意义

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/093605_b8cc18e5_5550632.png "屏幕截图.png")

#### 7.5.3 Newton迭代法的变形

##### 0x01 割线法

万一一阶导数不存在，我们怎么办？我们可以对其进行替代(一阶差商)：
$$
f^{'}(x_k)≈\frac{f(x_{k-1})-f(x_k)}{x_{k-1}-x_k}
$$
割线法迭代公式：
$$
x_{k+1}=x_k-\frac{x_k-x_{k-1}}{f(x_k)-f(x_{k-1})}f(x_k)
$$

##### 0x02 Newton下山法

Newton迭代法可能会出现振荡，或者由于初值选择的不好导致不收敛的情况，因此我们有下式：
$$
|f(x_{k+1})| < |f(x_k)|
\\x_{k+1}=x_k-\lambda\frac{f(x_k)}{f^{'}(x_k)}
$$

#### 7.5.4 Newton迭代法的推广

之前我们都是在解一元方程。现在假设我们有n个变元的**非线性方程组**。
$$
\vec{F}(\vec{x})=\vec{0}\\
\vec{F}(x)=\begin{bmatrix}
f_1(x_1,x_2,...,x_n)\\
...\\
f_n(x_1,x_2,...,x_n)
\end{bmatrix}_{(n×n)},\;
\vec{x}\begin{bmatrix}
x_1\\
x_2\\
.\\
.\\
.\\
x_n
\end{bmatrix}
$$
这些方程里只要有一个不是线性方程，就构成了一个非线性方程组。那么它的迭代公式为：

<img src="https://images.gitee.com/uploads/images/2021/1018/101845_11374b47_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:150%;" />

