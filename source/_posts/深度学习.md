---
title: 深度学习
declare: true
date: 2021-07-19 10:21:02
tags: [深度学习]
categories: [机器学习]
toc: true
---



<meta name="referrer" content="no-referrer" />  

<!--more-->

# 深度学习

[TOC]

## Part 0 引入

在人工智能中的一个火热分支就是深度学习，而且这种工具十分好用。所以要学习它。本文章需要读者具有机器学习的基础知识。本博客的源教程来自[吴恩达-深度学习](https://www.bilibili.com/video/BV1FT4y1E74V)，在此感谢Up主的搬运和吴恩达老师的教导。

## Part 1 神经网络与深度学习

### 1.1 神经网络导入

还是以房价预测为例，我们可以应用最简单的线性回归算法对房价进行预测，这可能是最简单的一个神经网络了。已知房屋面积，想预测房屋价格

![输入图片说明](https://images.gitee.com/uploads/images/2021/0903/144408_2d2531a1_5550632.png "屏幕截图.png")

线性回归的假设函数就是一个神经元（上图中的假设函数其实是一种名叫ReLU激活函数）。

神经网络则是由这些神经元搭建而成的，神经元就像乐高中的积木块一样。

我们把特征升级一下，现在特征包括了(房屋大小，卧室数目，邮编地址，平均购买人工资)

我认为：

1. (房屋大小，卧室数目)可以体现出可容纳的家庭人数

2. (邮编) 体现出周围房屋信息化是否发达

3. (邮编，平均工资) 体现出周围是否有好学校

这些因素综合到一起，可能是影响房价的原因，那么我们就可以画出这样的神经网络：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0903/145417_b9cd7162_5550632.png "屏幕截图.png")

有趣的是，我们没有必要指明哪些特征组合在一起有什么意义，最终我们的神经网络是这样的：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0903/145713_ee869df5_5550632.png "屏幕截图.png")



我们输入特征向量，经过中间的**隐藏层**，最后拿到结果，我们会让神经网络自己决定隐藏层中神经元所代表的含义。

用神经网络来进行监督学习很常见，这里列一个表格稍稍看一下深度学习的应用场景：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0903/150421_795b1cfb_5550632.png "屏幕截图.png")

普通的场景下，如房价预测，广告点击预测，我们用普通神经网络就可以解决(SNN),像是图像识别这类与图像打交道的，我们常用CNN算法，如果是语音，文字这种序列化的数据，我们常用RNN算法，应用了图像和雷达信息的自动驾驶则需要复杂的混合架构神经网络。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0903/150850_18ff5fb4_5550632.png "屏幕截图.png")

像上图中模型的含义，在后来的学习中会逐步揭晓，同时进行实现。

在深度学习中用到的数据可能是**结构化数据(Structured Data)**也可能是**非结构化数据(Unstructured Data)**。

结构化数据，那就是能够组织成数据库中的表结构的数据，非结构化数据可能是音频，图像，文字等。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0903/151248_fd149ef3_5550632.png "屏幕截图.png")

托了神经网络的福，计算机对这种非结构化数据的处理越来越好了。

### 1.2 二分类问题 (Binary Classification)

回到了一个基础的问题上，如何对数据集中的数据进行二分类？例子如下：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0903/153329_fc7eab6b_5550632.png "屏幕截图.png")

我们想识别出一个图片中是否有猫，有为1，没有为0.

一张图片是由**3个颜色矩阵表示的**，我们把每个矩阵都按行展开，构成一个列向量，这就是特征向量x，如果图片是(64\*64)像素的，那么特征向量的维数是64\*64\*3=12288,为了描述问题，我们引入一些符号：
$$
(x,y)表示一个样本\\
x∈R^{n_x},y∈\{0,1\}\\
m为训练集大小，训练集可以描述为\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...\}\\
m_{test}为测试集大小\\
为了简化运算，我们把特征向量按列构成矩阵X=\begin{bmatrix}
|&|&|&|\\
x^{(1)}&x^{(2)}&...&x^{(m)}\\
|&|&|&|
\end{bmatrix}_{(n_x×m)}\\
标签Y=[y^{(1)}\;y^{(2)},...,y^{(m)}]_{(1×m)}
$$

#### 0x01 Logistic Regression

Logistic 回归的主要思想是：已知特征向量x，现在想求出在特征向量为x的条件下为类1的概率，即P(y=1|x)，我们可以按照线性那样设计假设函数：
$$
h_\theta(x)=\theta^Tx+b
$$
但是这样会出现一些荒谬的错误，这个函数无法保证函数值在[0,1]之间，即不满足概率的基本公理。这显然是不合适的，所以我们不妨做如下改动:
$$
z=\theta^Tx+b\\
y_{predict}=sigmoid(z)\\
sigmoid(z)=\frac{1}{1+e^{-z}}
$$
其中，sigmoid函数长这样:

![输入图片说明](https://images.gitee.com/uploads/images/2021/0904/140519_79e50282_5550632.png "屏幕截图.png")

这样我们就可以把函数值约束在[0,1]间。这样我们就解决了假设函数的设计。接下来开始求θ和b。

#### 0x02 Logistic Regression Cost function

我们的最终期望的结果是**让预测值和真实值尽可能地相等**。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0904/141134_1fae9382_5550632.png "屏幕截图.png")

那么我们需要一个来**衡量单个样本中真实值与预测值之间的函数**，这个就是**损失函数（Loss function）**,这个函数的值当然是**越小越好**，这样预测误差才能尽量小。

在逻辑回归中，损失函数是这样定义的：
$$
L(y_{pre},y)=-(y\;log\;y_{pre}+(1-y)\;log\;(1-y_{pre}))
$$
举例说明其正确性:

> 假设此时有个y=1的样本，那么损失函数变为:
> $$
> L(y_{pre},y) = -y\;log\;y_{pre}
> $$
> 只有当y~pre~ 尽量大时，整个函数值才会变小。
>
> 同理现在有一个y=0的负样本，损失函数变为:
> $$
> L(y_{pre},y) = -(1-y)\;log\;(1-y_{pre})
> $$
> 只有当y~pre~尽量小(接近0)时【0<=y~pre~<=1】，整个损失函数值才会变小。
>
> 综上就可以下这样一个断言:
>
> **当预测值接近真实值时,此函数的值会变小，因此损失函数的功能合法，存在合理。满足了"让预测值和真实值尽可能地相等"这一预期。**

单个样本的误差-损失函数定义完成了，那么我们看看针对整个训练集上的误差-**代价函数(Cost function)**的定义：
$$
J(\theta,b)=\frac{1}{m}\sum^{m}_{i=1}L(y^{(i)}_{pre},y^{(i)})\\=-\frac{1}{m}\sum_{i=1}^m(y^{(i)}\;log\;y_{pre}^{(i)}+(1-y^{(i)})\;log\;(1-y_{pre}^{(i)}))
$$

#### 0x03 梯度下降(Gradient Descent)

为得到模型参数我们需要使用梯度下降算法进行求解。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0905/144450_6a679d71_5550632.png "屏幕截图.png")

在代价函数J中，只有模型参数**w (θ)和b**是未知的，且函数是个凸函数，这也就意味着它是一个高维曲面，而且**只有一个全局最小值**。

那么为了让其能找到最小值，那么我们需要随机初始化w和b，然后**沿着曲面变化速度最快的方向（方向导数最大的地方--梯度）找到全局最小值**。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0905/145413_c1a43cbb_5550632.png "屏幕截图.png")

对于上面这个曲线，我们想找到最小的w，梯度下降算法可表示为：
$$
Repeat\{\\
\;\;w:=w-\alpha\frac{\text{d}J(w)}{\text{d}w}
\\\}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/0905/150000_376a255a_5550632.png "屏幕截图.png")

#### 0x04 导数 (Derivatives)

导数的几何意义是斜率，直观理解如下图所示:

![输入图片说明](https://images.gitee.com/uploads/images/2021/0905/151108_819c43ef_5550632.png "屏幕截图.png")

#### 0x04 Logistic Regression的梯度下降

假设目前特征向量是二维的:

![输入图片说明](https://images.gitee.com/uploads/images/2021/0908/141924_0dceedbf_5550632.png "屏幕截图.png")



![输入图片说明](https://images.gitee.com/uploads/images/2021/0908/142335_6ae222f3_5550632.png "屏幕截图.png") 

为了知道L的梯度，我们需要对其进行复合求导：
$$
1.计算d_a=\frac{\text{d}L(a,y)}{\text{d}a}(y已知)=-\frac{y}{a}+\frac{1-y}{1-a}\\
2.计算\frac{\text{d}a}{\text{d}z}=a(1-a)\\
3.d_z = \frac{\text{d}a}{\text{d}z}\frac{\text{d}L(a,y)}{\text{d}a}=\frac{\text{d}L(a,y)}{\text{d}z}=a-y\\
4.\frac{\text{d}L(a,y)}{\text{d}w_1}=x_1d_z
\\
同理:d_{w_2}=x_2d_z\;d_b=d_z
$$
从下向上看就是数学中正常的偏导数计算方法，使用链式法则一层一层算，从上向下看就是反向传播的过程。

那么对于整个数据集我们应该如何偏导数计算呢？

![输入图片说明](https://images.gitee.com/uploads/images/2021/0908/145603_c5a63495_5550632.png "屏幕截图.png")

整个数据集的误差是代价函数值，等式两边同时求偏导，就可以得到答案。

最终就是把**每一项的损失函数的偏导数算出来,加和取平均**。

那么其梯度下降中的一次迭代可描述为：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0908/150157_d3452b0c_5550632.png "屏幕截图.png")

#### 0x05 向量化

在深度学习中，写for循环是十分低效的，所以我们需要对上述过程向量化。利用线性代数知识降低运算量。

首先先看正向传播：
$$
z^{(i)}=w^Tx^{(i)}+b\;①\\
a^{(i)}=\sigma(z^{(i)})②\\
X=\begin{bmatrix}
|&|&|&|\\
x^{(1)}&x^{(i)}&...&x^{(m)}\\
|&|&|&|
\end{bmatrix}_{(n_x×m)}
$$

$$
设:w=\begin{bmatrix}
|\\
|\\
|\end{bmatrix}\\
①<=>w^TX+b<=>z=numpy.dot(w.T,X)\\
sigmoid(z)=\frac{1}{1+e^{-z}}\\
②<=>a=sigmoid(z)
$$

反向传播求梯度：
$$
d_z^{(i)}=a^{(i)}-y^{(i)}\\
A=[a^{(1)}\;a^{(2)},...,a^{(m)}]\\
Y=[y^{(1)},y^{(2)},...,y^{(m)}]\\
d_Z=A-Y\\
d_b= \frac{1}{m}\sum^{m}_{i_1}d_z^{(i)}=>\frac{1}{m}numpy.sum(d_Z)\\
d_w=\frac{1}{m}Xd_Z^T\\
=\frac{1}{m}\begin{bmatrix}
|&|&|&|\\
x^{(1)}&x^{(i)}&...&x^{(m)}\\
|&|&|&|
\end{bmatrix}_{(n_x×m)}\begin{bmatrix}
d_z^{(1)}\\
d_z^{(2)}\\
...\\
d_z^{(m)}
\end{bmatrix}_{(m×1)}\\
=\frac{1}{m}\begin{bmatrix}x^{(1)}_1d_z^{(1)}+...+x^{(m)}_{1}dz^{(m)}\\
x^{(1)}_2d_z^{(2)}+...+x^{(m)}_{2}dz^{(m)}\\
...\\
x^{(1)}_{n_x}d_z^{(1)}+...+x^{(m)}_{n_x}dz^{(m)}\\
\end{bmatrix}\\
=
\begin{bmatrix}
d_{w_1}\\
d_{w_2}\\
...\\
d_{w_{x_n}}\\
\end{bmatrix}_{n_x×1}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/0910/163341_a4a4c2df_5550632.png "屏幕截图.png")

这就是Logistic回归的向量化

<br>

## Part 2 神经网络基础

### 2.1 神经网络概览

![输入图片说明](https://images.gitee.com/uploads/images/2021/0916/154354_34335e30_5550632.png "屏幕截图.png")

上图为神经网络的示意图，其中“[i]”代表第i层，特征向量输入的地方是输入层，中间由于不需要人工参与，称之为隐藏层，最后的输出结果为输出层。一般而言，我们不单独计算输入层，所以上图为2层神经网络。

那么，在神经网络中，每个神经元都在干什么呢？以logistic regression 为例：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0916/155006_9f3ccabd_5550632.png "屏幕截图.png")

一个神经元其实由两部分运算构成：

1. 假设函数值 （z）
2. 激活函数值 （a）

最终神经元会将**激活函数值做为下一层的输入**，直到正向传播完整个神经网络。

![输入图片说明](https://images.gitee.com/uploads/images/2021/0916/155728_55faf7d3_5550632.png "屏幕截图.png")

由于每个神经元都在进行相同的运算，所以可以把上述过程向量化，这样就可以轻松地描述神经网络的计算过程。
$$
a^{[l](i)}:代表第i个样本的第l层的激活函数值构成的向量
$$
计算整个数据集的结果，如果不将其向量化，它长这样：

![输入图片说明](https://images.gitee.com/uploads/images/2021/0927/131118_951d7cae_5550632.png "屏幕截图.png")

使用for循环对每个样本进行一次计算。重复m次。

所有样本可以构成矩阵X：
$$
X=\begin{bmatrix}
|&|&|&|\\
x^{(1)}&x^{(i)}&...&x^{(m)}\\
|&|&|&|
\end{bmatrix}_{(n_x×m)}
$$


那么神经网络可改写为:
$$
Z^{[1]}=W^{[1]}X+b^{[1]}\\
A^{[1]}=\sigma(Z^{[1]})\\
Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}\\
A^{[2]}=\sigma(Z^{[2]})\\
Z^{[1]}=\begin{bmatrix}
|&|&|&|\\
z^{[1](1)}&z^{[1](2)}&...&z^{[1](m)}\\
|&|&|&|
\end{bmatrix}\\
A^{[1]}=\begin{bmatrix}
|&|&|&|\\
a^{[1](1)}&a^{[1](2)}&...&a^{[1](m)}\\
|&|&|&|
\end{bmatrix}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/0927/133649_a746e4f6_5550632.png "屏幕截图.png")

### 2.2 激活函数 (Activation functions)

之前我们已经使用过激活函数了，只是没有提到这个名词。之前的$\sigma(x)=\frac{1}{1+e^{-z}}$就是名为sigmoid的激活函数。将其向下平移一个单位得到双曲正切函数tanh，它也可以作为神经元的激活函数，有时效果由于sigmoid函数：
$$
tanh(z)=\frac{e^z-e^{-z}}{e^z+z^{-z}}
$$
![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/132123_7b5e59ce_5550632.png "屏幕截图.png")

然而，这俩函数都有一个缺点，**当z特别大或特别小时，函数的导数(梯度)趋向于0**，这在梯度下降中是十分不好的现象（意味着每次迭代基本没有变化）。因此我们推导出一个新的激活函数：**修正的线性单元(rectified linear unit) ReLU**,它长这样

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/132711_827a1076_5550632.png "屏幕截图.png")

选择的经验是：如果进行的是二元分类任务，输出层使用sigmoid函数，其它层使用ReLU。其它任务所有层默认为ReLU

##### 为什么需要激活函数

如果没有激活函数，也称之为使用恒等激活函数。那么神经网络就变成了一个线性组合，既然是一个线性组合，我们何必又要设计神经网络呢？直接用线性代数计算不就可以了吗？

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/133926_2f914740_5550632.png "屏幕截图.png")

如果不引入非线性的函数，那么我们就无法找到那些非线性函数，也就无法解决问题。可能使用线性激活函数的地方，有。应该是在回归问题的输出层上。**为了寻找非线性函数，我们引入了激活函数这一概念。**

### 2.3 激活函数的导数

以sigmoid函数为例，求导:
$$
g(z)=\frac{1}{1+e^{-z}}\\
g^{'}(z)=g(z)[1-g(z)]
$$
当z很大或很小时，导数为0，从图像上也可以看出，z=0时，导数为$\frac{1}{4}$.

然后看tanh的导数:
$$
tan'h(x)=(\frac{e^x-e^{-x}}{e^x+e^{-x}})^{'}=\frac{(e^x+e^{-x})^2-(e^x-e^{-x})^2}{(e^x+e^{-x})^2}=\\
1-(tanh(x))^2
$$


![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/135348_95dbcd23_5550632.png "屏幕截图.png")

最后看看两种ReLu函数的导数：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/140507_b62b4638_5550632.png "屏幕截图.png")

### 2.4 神经网络的梯度下降

这里只给结论，不给证明，证明在我有能力推导的时候再给出吧：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1001/151612_4e8bc9f0_5550632.png "屏幕截图.png")

### 2.5 随机初始化

如果将所有的权重矩阵置为0，而不是随机数。也就意味着所有神经元实际上是在计算同一个函数，多个隐藏层的计算就毫无意义。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1005/151735_47a41ea0_5550632.png "屏幕截图.png")

为什么上图中乘0.01，这是因为在sigmoid函数中，当x过大或过小时，梯度很小(斜率不明显)，为了能够快速地收敛到局部最小值，我们将x看作一个较小的数。

### 2.6 深层神经网络

所谓深层神经网络是针对神经网络规模而言的，但是基本原理和之前介绍的神经网络是一样的。它们都有正向传播和反向传播。让我们来看一看和之前学的有没有差别。

正向传播：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1011/141223_ec3f5576_5550632.png "屏幕截图.png")

反向传播：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1011/141556_7074a161_5550632.png "屏幕截图.png")

![输入图片说明](https://images.gitee.com/uploads/images/2021/1012/114735_c2302765_5550632.png "屏幕截图.png")

和之前学的一模一样。而且还有一些规律，这有助于我们减少Bug的产生，通过观察神经网络，**在单样本的情况下**我们得出第l层的权重和偏置及其导数有如下规律：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1011/143702_27659801_5550632.png "屏幕截图.png")

向量化后是这样的：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1011/144121_1b407377_5550632.png "屏幕截图.png")

既然和2层神经网络的形式差不多，为什么我们需要使用深层神经网络呢？

对于图像识别而言，深度神经网络是这样做的。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1011/145327_b65d24c0_5550632.png "屏幕截图.png")

浅层神经元可能在进行图像边缘的识别，往深了走一层，可能在识别一些小的部位，比如眼睛，耳朵，鼻子，再往深了走就是把这些小部件进行拼凑，进而达成人脸识别的目的。

#### 0x01 参数与超参数

我们的参数其实就是神经网络中每层的权重和偏置，即：

$W^{[1]},b^{[1]},W^{[2]},b^{[2]}...$

但是有些参数会影响到我们要求的参数比如：**学习率，隐藏层数目，每层的神经元数目,momentum，mini batch...**我们称这些为**超参数（hyperparameter）**

<br>

## Part 3 深度学习基础

### 3.1 偏差和方差

高偏差其实就是欠拟合问题，模型没有被训练的很好。

而高方差问题是过拟合问题，指的是在训练集上的误差较大但是验证集上的误差很小。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/141028_d1952198_5550632.png "屏幕截图.png")

在低维数据的情况下，我们还可以通过可视化的手段来观察，模型是否出现偏差和方差问题。但是当数据维度高时，我们是不可能画出分类边界这类东西的。因此我们需要使用数值来描述上述问题：

**训练集误差**，**验证集误差**，**最优误差**

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/141434_b1df91aa_5550632.png "屏幕截图.png")

那么如何解决上述问题呢？

![输入图片说明](https://images.gitee.com/uploads/images/2021/1013/142603_8201f14a_5550632.png "屏幕截图.png")

对于偏差问题，我们可以构建更庞大的网络结构，对于方差问题我们可以添加数据，正则化，或者优化网络结构。

### 3.2 正则化

正则化其实是在代价函数中添加一项可以惩罚模型参数的项。以Logistic Regression为例：
$$
J(w,b)=\frac{1}{m}\sum_{i=1}^mL(y_{pre},y)+\frac{\lambda}{2m}||w||^2
$$
我们称后面那项为L2正则化。因为它是对向量取的平方范数。

我们也有L1正则化，定义如下：
$$
\frac{\lambda}{2m}||w||
$$
在深层神经网络中，我们的代价函数可以如下表示：
$$
J(W^{[1]},b^{[1]},W^{[2]},b^{[2]},...,W^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^mL(y_{pre},y)+\frac{\lambda}{2m}\sum_{l=1}^L||W^{[l]}||^2
$$

$$
W^{[l]}.shape=(n^{[l-1]},n^{[l]})\\
\sum_{l=1}^L||W^{[l]}||^2=\sum_{i=1}^{n^{[l-1]}}\sum_{j=1}^{n^{[l]}}||W_{ij}||^2
$$

矩阵的平方范数我们称之为：**Frobenius 佛罗贝尼乌斯范数**

那么其导数会变为：
$$
d_W^{[l]}=反向传播的结果+\frac{\lambda}{m}W^{[l]}\\
w^{[l]}:=w^{[l]}-\alpha\;d_W^{[l]}
$$

#### 3.2.1 dropout 正则化

dropout正则化的基本思想是，在训练神经网络时，随机地抛弃一些神经元，来防止模型过拟合现象的出现。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/134400_161e29d3_5550632.png "屏幕截图.png")
![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/134408_3201bcd6_5550632.png "屏幕截图.png")

我们以一个三层网络为例，演示一下如何dropout

```python
keep_prob = 0.8
d3=np.random.rand(a3.shape[0],a3.shape[1])<keep_prob
a3 = np.multply(a3,d3)#False==0,True==1
a3/=keep_prob#补偿被删除的神经元，保证a3的期望不变
```

首先生成一个布尔矩阵，矩阵中80%是有效的20%被抛弃

然后，每一次梯度下降都使用dropout。在测试时不使用dropout

然而，它为什么好使呢？

由于dropout的存在，L+1层的神经元不能完全依赖L层的输入，因为在L层中的任意若干个神经元都可能会被消除，所以L+1层的神经元们会把权重尽量平均地分配给L层的神经元的输出，也就减小了权重矩阵的平方范数（佛罗贝尼乌斯范数）

对于神经元个数比较多的层，我们可以扔得多一些，对于神经元个数较少的层，我们可以多保留一些。

#### 3.2.2 其它预防过拟合的方式

##### 0x01 Data augmentation

通过对原始图片进行水平翻折，旋转放大，可以达到扩充数据集的目的，进而减小过拟合问题。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/140835_1715359a_5550632.png "屏幕截图.png")

##### 0x02 Early stopping

把模型在训练集和测试集上的代价函数值画出来，找到一个较好的迭代次数，提前停止训练。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/141211_7d3588f3_5550632.png "屏幕截图.png")



### 3.3 归一化 (Normalization)

为了加快训练速度，我们一般采取归一化的输入，什么是归一化呢？

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/142000_2520b629_5550632.png "屏幕截图.png")

归一化的目的是消除两个量纲下数值差距所带来的影响。

归一化分为两步：

1)均值归一化，算每个特征的均值

2)方差归一化，算每个特征的方差

**天坑：**在训练集计算出的均值和方差，**请在测试集中使用相同的归一化参数！！！**

归一化的作用可以从下图中看出：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1018/142909_0d1a2765_5550632.png "屏幕截图.png")

归一化后，可以使代价函数更规则，在设置学习率的时候可以稍微调大一些。在对其进行优化时，梯度下降收敛效果会更好。

### 3.4 梯度消失和梯度爆炸(Vanishing/Exploding gradient)

字面意思，在训练深层网络时，有时可能梯度会很大，有时梯度可能会变得很小，这两种极端都对训练产生了不好的影响。

举个例子，假设我们拥有下面这样一个神经网络结构，采用**线性激活函数a(z)=z，偏置为0**:

![输入图片说明](https://images.gitee.com/uploads/images/2021/1020/134155_252d8a92_5550632.png "屏幕截图.png")

如果这样，那么是不是我们的输出可以这样表示：
$$
y_{pre}=W^{[L]}W^{[L-1]}...W^{[1]}x\\
z^{[1]}=W^{[1]}x\\
a^{[1]}=g(z^{[1]})=z^{[1]}\\
$$
假设初始的权重矩阵为:
$$
W^{[L]}=\begin{bmatrix}
0.5&0\\
0&0.5
\end{bmatrix}
$$
那么：
$$
y_{pre}=W^{[L]}\begin{bmatrix}
0.5&0\\
0&0.5
\end{bmatrix}^{L-1}x
$$
w<1,激活函数以指数级别减小，如果w>1，又是指数级别的增加。

### 3.5 权重矩阵随机初始化

深层神经网络权重初始化可以有效减小梯度爆炸或消失发生的概率。一般而言，对于不同的激活函数，我们采取不同的随机初始化方式。

使用ReLU，推荐使用下面这种初始化方式：
$$
W^{[L]}=np.random.rand((shape))*np.sqrt(\frac{2}{n^{[L-1]}})
$$
使用tanh激活函数，推荐使用如下的权重矩阵初始化方式：
$$
W^{[L]}=np.random.rand((shape))*np.sqrt(\frac{1}{n^{[L-1]}})\\
W^{[L]}=np.random.rand((shape))*np.sqrt(\frac{2}{n^{[L-1]}+n^{[L]}})
$$

### 3.6 梯度检验

写反向传播的时候，是否对算出的结果产生疑问，我算的这玩意对不对？

这次我们将讨论如何在反向传播时进行梯度检验，以求我们实现的算法是正确的。

通过双侧差商，我们可以用来近似某一点的导数：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1020/144013_d3a15167_5550632.png "屏幕截图.png")

同理，在深层学习网络中我们也可以这样做。我们首先需要把我们所有的模型参数和所求出的梯度展开成一个“超级大向量”。如下形式

![输入图片说明](https://images.gitee.com/uploads/images/2021/1020/144235_70aa2d95_5550632.png "屏幕截图.png")

然后开始计算每一个参数的差商结果，得到一个向量$d_{\theta_{approx}}$：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1020/144423_f7471da9_5550632.png "屏幕截图.png")

最后我们要对梯度下降出来的大参数向量$d_{\theta}和d_{\theta_{approx}}$进行比较。我们这里选择计算它们的欧几里得距离，但是对其进行些许修改：
$$
result = \frac{||d_{\theta_{approx}}-d_{\theta}||_2}{||d_{\theta_{approx}}||_2+||d_{\theta}||_2}
$$
这个值越小，就证明反向传播的结果和梯度的估计值越接近。通常情况下量级达到$10^{-7}$是不错的，$10^{-5}$可能会有几项存在Bug，要是误差再大就要考虑考虑反向传播算法是不是实现错误了。

**使用技巧与注意事项**

1. 梯度检测请只在Debug的时候使用，训练的时候请关掉它
2. 如果真的查出Bug了，**检查每一项**，并试着找出Bug。看看是哪一层的哪个参数出现了问题。
3. 注意正则化，如果代价函数使用了正则化。那么梯度检测也要包括正则化系数
4. 梯度检测不能和dropout一起使用

<br>

## Part 4 深度学习优化算法

### 4.1 Mini-batch gradient descent

我们之前接触的梯度下降算法名为**Batch Gradient descent**，之前的一个Batch，就默认表示整个数据集。

现在要介绍的是把一个数据集按步长分成若干个子集，然后进行梯度下降的算法。

众所周知，我们的数据集和标签可以用矩阵的形式来表示。在批量梯度下降算法中，我们必须遍历整个数据集才能更新模型参数。当数据集很大的时候，假设500万条数据。每一步下降的速度是很慢的，因为它要算500万行的数据。

有没有一种方法能够加速参数的更新？

本节就介绍一种更快的模型参数更新方法。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1024/110545_11c6e028_5550632.png "屏幕截图.png")

在上图中，假设有500万条数据。我们以1000为步长对数据集分成了5000份。$x^{\{t\}},y^{\{t\}}$代表第t份batch。

那么mini-batch的工作可如下表示：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1024/111512_fffe94f5_5550632.png "屏幕截图.png")

上面整个执行一遍是梯度下降中的一次迭代。如果要控制迭代次数需要在外面再加一层循环。

分份的梯度下降和按整体进行梯度下降的代价函数收敛情况可用下图描述：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1024/133743_8b743fbf_5550632.png "屏幕截图.png")

那么mini-batch梯度下降包括了两种特殊的梯度下降法：

1.当每一组中的数据个数为1时，此时变成了随机梯度下降。

2.当取m时，就是普通的批量梯度下降。

它们的收敛情况可画出如下的图：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1025/155307_af4d3f7b_5550632.png "屏幕截图.png")

$\color{blue}{蓝色是批量梯度下降算法的代价函数优化示意图},\color{purple}{紫色为随机梯度下降},\color{green}{绿色为mini-batch的优化示意图}$

其中最小值点在等高线图的中心处。

Batch梯度下降的缺点是：**每次进行参数更新时需要很长的等待时间（计算整个数据集）**

随机梯度下降的缺点是：**1.永远没有一个真正意义上的最小值。2.失去了向量化的能力，不能使用线性代数求解**

综合两种梯度下降的缺点进行折中与改进，得出mini-batch是较好的一种优化算法。

###### 指数加权平均

接下来会介绍很多在mini-batch梯度下降上改进的更好的数值优化算法。

首先引入指数加权平均这一概念。

什么是指数加权平均呢？举下图这样的一个例子：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1025/160802_9cc91cbe_5550632.png "屏幕截图.png")

我们有伦敦365天的温度，观测出来的是（第i天，温度）这样的点，现在我们想拟合出一条曲线来描述温度随时间推移的变化，我们可以用如下公式来定义：
$$
v_0=0\\
v_1 = 0.9*v_0+0.1*\theta_1\\
v_t=0.9*v_{t-1}+0.1*\theta_t
$$
那么公式可描述为：
$$
v_t = \beta*v_{t-1}+(1-\beta)*\theta_t
$$
上面这个东西画图能长成什么样呢？

<img src="https://images.gitee.com/uploads/images/2021/1025/161246_77a7654f_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:80%;" />
$$
\beta=0.9可以看作平均了\frac{1}{1-\beta}=10天的平均天气,上图中为\color{red}{红色曲线}\\
\beta=0.98可以看作平均了50天的天气,上图中为\color{green}{绿色曲线}
$$
我们再极端一些，令$\beta=0.5$,相当于只平均之前两天的天气，那么会得到下面这条黄色的曲线：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1025/161717_ecb40806_5550632.png "屏幕截图.png")

参数$\beta$越大，对于历史数据就越看重，新来的数据就显得没那么重要。

上面这个东西在统计学里称为**指数加权移动平均值**。把上面这个迭代式展开可以得到如下这样的一个东西：
$$
v_{100}=0.1*\theta_{100}+0.1*0.9*\theta_{99}+0.1*(0.9)^2*\theta_{98}+...
$$
仔细观察一下这个式子，会发现它其实由两部分组成：

1.**已收集的历史数据**

2.**指数衰减函数**

其中指数衰减函数长这样：

```python
import numpy as np
import matplotlib.pyplot as plt

def func(x,beta = 0.9):
    y = []
    for i in range(0,len(x)):
        res = (1-beta)*(beta**i)
        y.append(res)
    return y

x = np.arange(1,10+1,0.1)
y = func(x,beta=0.9)
print(x)
print(y)

plt.plot(x,y)
plt.show()
```

<img src="https://images.gitee.com/uploads/images/2021/1026/151244_30956684_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:50%;" />

以上是只有一个参数时的平均值计算方法。

之后会介绍多个参数时的平均值求法,毕竟我们的学习任务不可能都是只有一个特征值的。

###### 偏差修正

在之前的例子中其实存在一个问题，温度预测的迭代公式如下：
$$
\beta = 0.98\\
v_t = \beta\;v_{t-1}+(1-\beta)\;\theta_t\\
v_0=0\\
v_1=0+0.02*\theta_1=0.08℃\\
v_2=0.98*0.02*\theta_1+0.02*\theta_2=0.181568℃
$$
第一天的温度为4℃，第二天为9℃，但是公式拟合推导的结果一个0.08，一个是0.18相差甚远。这个现象就是由于刚开始样本量小所导致的偏差问题而产生的。那么如何修正这个偏差呢？
$$
v_t = \beta\;v_{t-1}+(1-\beta)\;\theta_t\\
v_t:=\frac{v_t}{1-\beta^t}
$$
经过这样的更改我们会得出:
$$
t=1:\frac{0.98*v_0+0.02*\theta_1}{1-0.98^1}=4\\
t=2:\frac{v_2}{1-(0.98)^2}=\frac{0.0196*\theta_1+0.02*\theta_2}{0.0396}=6.25
$$
而且随着天数的增加,修正的幅度将会越来越小。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/134944_d9daf638_5550632.png "屏幕截图.png")



我们没有修正之前的曲线是那条紫色的，修正后是绿色的，可以看出在数据量变大的时候，有无偏差修正的效果相差无几。

### 4.2 动量梯度下降 (Gradient descent with momentum)

梯度下降的目的是找到优化目标的全局最小值。那么在收敛的过程中一定会出现如下这样的现象：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/135024_13495fc3_5550632.png "屏幕截图.png")



假设上图为优化目标的等高线图，红点为最小值。代价函数的收敛情况可描述为：在纵轴方向上会上下抖动，水平方向趋向于局部最小值。

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/135107_67b0b28f_5550632.png "屏幕截图.png")

我们如何才能减少纵向的抖动，进而减少迭代次数，达到加速算法收敛的目的呢？通过动量梯度下降算法就可以达到这一目的，算法描述如下：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/135145_d3b44a4d_5550632.png "屏幕截图.png")

```
v_{dw}=0,v_{db}=0
在第t次迭代
	通过mini-batch计算d_w,d_b:
		v_{dw} = βv_{dw} + (1-β)(d_w)
		v_{db} = βv_{db} + (1-β)(d_b)
		w := w - αv_{dw}
		b := b - αv_{db}
```

通过计算$v_{dW},v_{db}$来平均之前所计算的模型参数，减少纵向抖动的程度。

同时不止如此，我们假设模型参数是在优化目标上的一个点，通过$d_W,d_b$相当于推了这个点一把，给了一个加速度，同时由于$\beta<1$这个加速的过程不会永远持续下去。相当于在没到最小值之前油门踩到底，快到的时候，再踩刹车的这种感觉。

通过加权平均的方式加速算法的收敛。

### 4.3 RMSprop算法(Root mean square prop)

再介绍一种优化算法RMSprop，算法如下：

```
在第t次迭代
	通过mini-batch计算d_w,d_b:
		s_{dw} = βs_{dw} + (1-β)(d_w)**2
		s_{db} = βs_{db} + (1-β)(d_b)**2
		w := w-α(d_w/sqrt(s_{dw}))
		b := b - α(d_b/sqrt(s_{db}))
```

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/140202_3895e44e_5550632.png "屏幕截图.png")

它减少了竖直方向上的抖动，使得梯度下降结果类似于上图绿色的那个样子。

### 4.4 Adam(Adapt moment estimation) 优化算法 (很好用)

将Momentum和刚才的RMSprop结合起来会得到一个效果更好，适应性更强的的梯度下降算法，它就是Adam算法。算法的示意图长这样：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/141703_1ab4408f_5550632.png "屏幕截图.png")

$$
\;v_{dw}=0,s_{dw}=0,v_{db}=0,s_{db}=0\\
在第t次迭代
\;通过mini-batch计算d_w,d_b:\\
		v_{dw}=β_1v_{dw}+(1-β_1)d_w,\;\;v_{db}=β_1v_{db}+(1-β_1)d_b\;\;(momentum)\\
		s_{dw} = β_2s_{dw} + (1-β_2)(d_w)^2,\;\;s_{db} = β_2s_{db} + (1-β_2)(d_b)^2\;\;(RMSProp)\\
		v_{dw}^{corrected}=\frac{v_{dw}}{1-\beta_1^t},\;\;v_{db}^{corrected}=\frac{v_{db}}{1-\beta_1^t}\\
		s_{dw}^{corrected}=\frac{s_{dw}}{1-\beta_2^t},\;\;s_{db}^{corrected}=\frac{s_{db}}{1-\beta_2^t}\\
		w:=w-\alpha\frac{v_{dw}^{corrected}}{\sqrt{s_{dw}^{corrected}+\epsilon}},\;\;
		b:=b-\alpha\frac{v_{db}^{corrected}}{\sqrt{s_{db}^{corrected}+\epsilon}}
$$
第一部分计算梯度，没什么问题。

然后计算Momentum，使用之前momentum算法中的公式

再计算RMSprop，使用刚讲的计算RMSprop的方法。

在进行梯度下降前，进行偏差修正。

最后计算梯度。

那么这个算法的超参数有：

1.学习率$\alpha$（自己调）

2.Momentum参数$\beta_1=0.9$（默认值即可）

3.RMSprop参数$\beta_2=0.999$（默认值即可）

4.为确保分母不为0的$\epsilon=10^{-8}$（默认值即可）

### 4.5 Learning rate decay 学习率衰减

为什么要计算学习率衰减？

在mini-batch当中，由于每次取的是数据集的一个子集，会有噪声干扰收敛的方向，最终其实算法永远不会找到那个最小值，只会在周围徘徊。因为此时我们的学习率没有发生变化，当靠近最小值时，我们希望迈的步子小一点。但是之前从来没有这样去计算过，由此我们要计算学习率衰减，让优化算法更靠近最小值。

不衰减学习率时的代价函数收敛情况如下图蓝色曲线，而改变学习率的收敛情况类似于绿色曲线：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/143016_664a0d73_5550632.png "屏幕截图.png")

说到底，我们的目的就是一句话：**在学习初期时，用较大的学习率，快要收敛时，把学习率变小**

无论是在哪种梯度下降算法中，我们把**所有训练集数据都遍历过一次视作一次迭代的结束**。

那么我们的学习率可以定义成这样一种形式：
$$
\alpha=\frac{1}{1+decay-rate*迭代次数}\alpha_0
$$
当然，还有其它的方式，比如:
$$
\alpha=0.95^{迭代次数}\alpha_0\;\;\;\;(指数衰减)\\
\alpha=\frac{k}{\sqrt{迭代次数}}\alpha_0\\
...
$$

###### 局部最优解问题

在低维空间中，我们可能会认为局部最优解长成这个样子：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/150504_f1ba0c77_5550632.png "屏幕截图.png")

但实际上，这种思维方式代入到高维空间中是有失偏颇的，实际上，在高维空间中我们的优化目标更类似于这样的东西：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/150627_a84fdea5_5550632.png "屏幕截图.png")

假设我们的优化目标是一个15万维的函数，我们不太可能找到一个点使得在15万个方向上的导数都为0，所以在深层神经网络中，我们不需要担心局部最小值的问题，一般都在马鞍点附近。

但是有另一种情况是比较不好的（plateau 问题）。就是优化目标很平，类似下图，梯度很小，需要很长时间才能走到最小值处：

![输入图片说明](https://images.gitee.com/uploads/images/2021/1027/151004_0782cafe_5550632.png "屏幕截图.png")



这种情况，Adam算法和其它优化算法可以很好地解决这一问题。

### 4.6 Batch归一化 (Batch Normalization)

在之前我们知道了，通过对数据继续归一化，可以加速梯度下降法的收敛速度，那么进而思考一下，我们**能不能把隐藏层的输出也都归一化一下，加速计算模型参数W,b呢？**

<img src="https://images.gitee.com/uploads/images/2021/1101/135054_c1ba5b46_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:80%;" />

归一化$a^{[l]},企图加速计算w^{[l+1]},b^{[l+1]}$.

在学术界，对于归一化激活函数前的值和激活函数后的值(a,z),有所争论。这里使用归一化$z^{[l]}$的这种版本。
$$
\mu=\frac{1}{m}\sum_{i}z^{(i)}\\
\sigma^2=\frac{1}{m}\sum_i(z^{(i)}-\mu)^2\\
z^{(i)}_{norm} = \frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}}\\
z^{(i)}_{use} = \gamma z^{(i)}_{norm}+\beta \\
当\gamma=\sqrt{\sigma^2+\epsilon},\beta = \mu时:z^{(i)}_{use}=z^{(i)}_{norm}
$$

把计算过程描述以下应该是这样的：
$$
输入:a^{[l-1]}\;\;\;\;其中,b^{[l]}=0\\
1.\;z^{[l]}=a^{[l-1]}w^{[l]}+b^{[l]}\\
2.\;z^{[l]}_{norm}=normalize(z^{[l]})\\
3.\;z^{[l]}=\gamma z^{[l]}_{norm}+\beta^{[l]}\\
4.\;a^{[l]}=g(z^{[l]})
$$
同时这里存在一个小细节，那就是**如果使用了Batch正则化参数$b^{[l]}$恒为0，因为在第三步计算中补偿了所删除的部分**

把它和Mini-batch联系在一起的话，可描述为:
$$
for\;i\;in\;range(1,M):\\
\;\;\;\;进行X^{i}的前向传播\\
\;\;\;\; z^{[i]} = a^{[i-1]}w^{[l]}\\
\;\;\;\;z^{[i]} = norm(z^{[i]})\\
\;\;\;\;更新参数\\
\;\;\;\;w^{[i]} := w^{[i]}-αd_{w^{[i]}}\\
\;\;\;\;β^{[i]} := β^{[i]}-αd_{β^{[i]}}\\
\;\;\;\;γ^{[i]} := γ^{[i]}-αd_{γ^{[i]}}\\
$$

那么batch归一化是通过什么达到目的地呢？或者说它实际做了什么？

对于某一层神经元而言，它们的输出值是根据之前层上的神经元确定的，为了减少之前神经元对本层神经元的扰动，我们强行对上一层的输出值进行了度量统一，即使用$\beta,\gamma$对均值和方差进行统一。

说完了训练过程，我们如何应用它跑测试集呢？

从之前的式子中不难看出，对于每一层都存在一个均值和方差，但是由于我们使用的是mini-batch的方法，每一层神经元在不同batch的情况下的取值是不同的，所以此时我们需要使用**指数加权平均**这一方法来计算均值和方差。当然，也可以选择直接把整个数据集扔进去然后计算均值和方差。两种估计均值和方差的方法对模型都没有太大的影响。
$$
X^{1}:\mu^{1[l]},{\sigma^2}^{1[l]}\\
X^{2}:\mu^{2[l]},{\sigma^2}^{2[l]}\\
...\\
X^{m}:\mu^{m[l]},{\sigma^2}^{m[l]}\\
$$

### 4.7 多元分类-Softmax输出层

假如现在我们要识别的图片可以分为，苹果，香蕉，枇杷这三类，我们如何训练一个神经网络来分类呢？

在输出层之前我们都不需要进行太多的调整。我们的输出层可这样设置：

<img src="https://images.gitee.com/uploads/images/2021/1110/101415_90236aa0_5550632.png" alt="输入图片说明" title="屏幕截图.png" style="zoom:33%;" />

0代表其它类，1代表苹果，2代表香蕉，3代表枇杷

那么与之前不同的是我们在这一层使用Softmax激活函数：
$$
Input:(a^{[l-1](0)},a^{[l-1](1)},a^{[l-1](2)},a^{[l-1](3)})\\
Step1:s_1 = (e^{a^{[l-1](0)}},e^{a^{[l-1](1)}},e^{a^{[l-1](2)}},e^{a^{[l-1](3)}})\\
Step2:\frac{s_1}{numpy.sum(s_1)}\\
$$
举例，如果输出层接受到的输入为：$(3,-2,4,5.6)$，通过softmax映射后的结果为：$(0.0581775606,0.00039199732,0 .158143006,0.783287436)$

换句话说我们认为神经网络识别图片为枇杷的概率为78.33%，香蕉为15.81%

如果softmax层的结点为2，那么等效于Logistic Regression

应用了Softmax的神经网络如何计算代价函数值？

首先看单个样本的损失函数：

假设现在有张图片是苹果，那么其标签为$(0,1,0,0)$,神经网络的输出为:$(0.1,0.2,0.6,0.1)$

显然这个分类是错误的，那么对于单个样本我们可以这样计算其损失函数：
$$
l(y,y_{pred})=-y\;log(y_{pred})
$$
由于标签中只有第二位为1，那么我们的优化目标可写成：
$$
l(y,y_{pred})=-log(y_{pred})
$$
想让函数值变小就只能让$y_{pred}$变大，这达到了优化的目标

那么对于所有样本的代价函数可写作：
$$
J(y,y_{pred})=\frac{1}{m}\sum_{i=1}^ml(y^{(i)},y_{pred}^{(i)})
$$

<br>

## Part 5 卷积神经网络(Convolution Neural Network)

### 5.1 卷积运算的具体过程

![](https://images.gitee.com/uploads/images/2022/0714/145825_f22cc99b_5550632.png)

上图是一个垂直边缘检测的例子，最左侧的矩阵就是我们输入的图片(灰度图,无颜色通道)，中间的矩阵叫做Filter或者卷积核(kernal)，最右侧为卷积运算的输出结果。

卷积运算的方式非常简单，如下图所示:

![](https://images.gitee.com/uploads/images/2022/0714/150928_2fb1d10e_5550632.png "屏幕截图.png")

在计算机视觉研究的早些阶段，过滤器（卷积核）的值是固定的，比如下面这两个经典的过滤器(Sobel,Scharr)：

![](https://images.gitee.com/uploads/images/2022/0721/193347_7aa09448_5550632.png "屏幕截图.png")

它们都只能找出水平或竖直的边缘信息，若想检测任意角度的边缘信息。我们需要让计算机自己学习出卷积核中的值。利用反向传播算法计算卷积核的权重。之后的内容将围绕卷积核及其计算方式展开

### 5.2 Padding

pad 顾名思义，填充的意思。为什么在卷积中要有填充操作呢？

在卷积运算的时候，对于图片的四个边缘，卷积操作只会执行一次。这就使图片边缘的信息并不能得到充分的利用。这是第一点原因。

第二，经过卷积，原图片的尺寸会被缩小。假设我们有一个n×n的图片,f×f的卷积核那么我们最终卷积出来的图片大小为：
$$
(n-f+1,n-f+1)
$$
如果有一个100层的神经网络，每一层都做一次卷积，最后你输出的图片很有可能会变成1×1的图片。

那么为了解决上述问题，我们需要对原图片进行填充。

原理很简单，只需要在原图片的四周，填充宽度为p的0就可以了，如下图所示：

![输入图片说明](https://images.gitee.com/uploads/images/2022/0721/195528_9af6c860_5550632.png "屏幕截图.png")

上图绿色区域为灰度值0，白色区域是原图片。p是多少就在原图片外面加多少圈0，这就是填充。

经过填充的图片卷积之后的大小为:
$$
(n+2p-f+1,n+2p-f+1)
$$
若想让卷积后的图片大小和原图片大小保持相同，只需让p满足下面等式即可：
$$
p=\frac{f+1}{2}
$$
为了对称填充，p一般取偶数，卷积核的大小一般取奇数。

如果卷积运算不使用padding，则称为：**Valid Convolution**

如果卷积运算使用padding，则成为：**Same Convolution**

这就是padding的主要内容。

### 5.3  卷积步长 (Strided Convolution)

卷积步长也很好理解，之前我们卷积操作都是卷积核每次只移动一行或一列，现在我们移动指定步长来计算而已。如下图所示：

![输入图片说明](https://images.gitee.com/uploads/images/2022/0721/200319_0226f091_5550632.png "屏幕截图.png")

假设，原图片是n×n，卷积核为f×f，padding=p，步长stride=s,那么我们最终计算出的结果的矩阵维度是：
$$
(\frac{n+2p-f}{s}+1,\frac{n+2p-f}{s}+1)
$$
如果上述计算结果不是整数，则**向下取整**

  ### 5.4 三维卷积

彩色图片其实是有3个通道的矩阵，如果我们想对彩色图片进行卷积，此时我们的卷积核就应该是三维的。示意图如下所示：

![输入图片说明](https://images.gitee.com/uploads/images/2022/0726/110257_74d21601_5550632.png "屏幕截图.png")

三维的卷积运算也十分简单，每个通道上都进行普通的卷积然后把每个通道上的结果相加就得到了三维卷积的结果。**值得注意的是，卷积核的通道数要和图片的通道数完全相同**

![输入图片说明](https://images.gitee.com/uploads/images/2022/0726/110649_b6b3584e_5550632.png "屏幕截图.png")

下面还有一个问题，如果我对一张图片既想进行水平边缘检测又想进行垂直边缘检测的话应该如何设置卷积核呢？那就使用两种不同的卷积核，然后在最后输出中将他们叠加起来。如下图所示：

![输入图片说明](https://images.gitee.com/uploads/images/2022/0726/111437_1feb7ee0_5550632.png "屏幕截图.png")

### 5.5 单层卷积网络

对于一个单层卷积网络，他的结构可如下图所示：

![输入图片说明](https://images.gitee.com/uploads/images/2022/0802/150258_315d030c_5550632.png "屏幕截图.png")

简单介绍一下吧，上图中(3×3×3)的张量有两个，这是两个卷积核，对于每一个卷积的结果我们需要加上偏置然后执行非线性函数（上图中为ReLU）将得到的两个矩阵拼到一起就完成了一次前向传播操作。

那么，我有一个疑问，传播之后的结果张量的维度应该怎么计算呢？我们引入一些符号推导一下：
$$
设l是一个卷积层:\\
Input:n_{H}^{[l-1]}×n_{W}^{[l-1]}×n_c^{[l-1]}\;(n_c^{[l-1]}为通道数)\\
f^{[l]}:卷积核大小\\
p^{[l]}:padding大小\\
s^{[l]}:卷积步长\\
n_c^{[l]}:卷积核数量(单位:个)\\
1.根据定义l层的每个卷积核大小均为:f^{[l]}×f^{[l]}×n_c^{[l-1]}\\
2.单样本激活函数结果:a^{[l]} = n_{H}^{[l]}×n_{W}^{[l]}×n_c^{[l]}\\
3.权重矩阵W(张量):f^{[l]}×f^{[l]}×n_c^{[l-1]}×n_c^{[l]}(第l层每个卷积核的大小的和)\\
4.偏置b:1×1×1×n_c^{[l]}\\
5.l层数据集上激活函数结果:A^{[l]} = m×n_{H}^{[l]}×n_{W}^{[l]}×n_c^{[l]}\\
Output:n_{H}^{[l]}×n_{W}^{[l]}×n_c^{[l]},其中:\\
n_{H}^{[l]} = 下取整(\frac{n_{H}^{[l-1]}+2p^{[l-1]}-f^{[l-1]}}{s^{[l]}}+1)\\
n_{W}^{[l]} = 下取整(\frac{n_{W}^{[l-1]}+2p^{[l-1]}-f^{[l-1]}}{s^{[l]}}+1)
$$
然后我们来看一个卷积神经网络的例子：

![输入图片说明](https://images.gitee.com/uploads/images/2022/0802/153121_f619f42d_5550632.png "屏幕截图.png")

我们原始输入的图片假设为$39×39×3$的图片，然后想做图片分类或识别问题。

根据上述的记号定义,$n_{H}^{[0]}=n_W^{[0]}=39,n_c^{[0]}=3$

在第一层中我们的卷积核配置如下:

卷积核大小:$f^{[1]}=3$

卷积步长:$s^{[1]}=1$

padding:$p^{[1]}=0$

卷积核数量:$n_c^{[1]}=10$

根据公式，我们可以很轻松的算出来第一层卷积结果的张量维度为$37×37×10$
$$
37 = \frac{39+(2×0)-3}{1}+1
$$
同理根据第二层的卷积核配置可以推出第三层的卷积张量结果为$17×17×20$

最后一层的结果为：$7×7×40$

随着卷积层的增加，原图片大小缩小但通道数增加，在最后一层我们可以将$7×7×40$展开成一个1960的向量扔给softmax或logistic regression的假设函数让它算出结果即可。

在卷积神经网络的设计中，按功能划分可以分成三种层：

1. 卷积层(Convention):本层主要功能就是进行卷积，如同上述例子中展示的那样
2. 池化层(Pooling):之后讲
3. 全连接层(Fully Connected):之后讲

### 5.6 池化层 (Pooling)

池化其实就是对卷积结果再做一些操作，以**最大池化**为例，看一下它的作用。

![输入图片说明](https://foruda.gitee.com/images/1660615683826209119/屏幕截图.png "屏幕截图.png")

左侧矩阵是经过卷积算出来的一个矩阵，我们采用**一个2×2，步长为2的最大池化层**，那么顾名思义最大池化就是在2×2的范围内取最大值然后以步长为2的方式进行移动。如右侧矩阵所示的那样，每个颜色都对应着一次最大池化的结果，就红色而言，左侧矩阵部分最大值为3，所以最大池化结果就是3.

最大池化的作用是提升模型鲁棒性，只取卷积之后的**”最重要的特征“**

除了最大池化外，还有**平均值池化**，顾名思义就是把池化范围内的特征取均值得出结果。

池化操作本身没有权重需要学习，只有一些参数需要设置，比如池化层的大小，步长等。

池化后的矩阵大小计算方式和卷积相同，在此不再赘述。

### 5.7 一个卷积神经网络的案例

![输入图片说明](https://foruda.gitee.com/images/1660616097877745834/屏幕截图.png "屏幕截图.png")

一般而言当有权重参数需要学习的时候我们称之为一层，因此在上图中，conv1和pool1合在一起称为一层，conv2和pool2同理。**一张图片**经过两次卷积后，将经过pool2的张量拉成一个(400,1)的向量，然后进入全连接FC3变成(120,1)然后再经过FC4变成(84,1)最后扔进softmax函数中计算数字0-9的十个概率，概率最大的为预测结果。

我们为什么需要使用卷积呢？如果就是头铁全用全连接层来描述上面这个网络结构不可以吗？

以输入层到Layer1为例，从参数个数上看，全写成全连接会导致如下结果：

两层中间的权重参数个数为:32×32×3×28×28×6 = 14,450,688 （14M）,虽说以现在的技术手段也能计算，单数如果你的输入图片是1000×1000×3呢？

如果我们采用卷积，可以稍稍推导一下需要计算的参数个数。

每个卷积核是5×5，卷积之后的bias的1个，那么1个卷积核里有26个参数。

第一层卷积用6个卷积核，那一共也就算个6*26=156个参数

因此使用卷积可以大幅度减少模型参数防止模型过拟合。

那卷积为啥可以减少模型参数呢？

1. 参数共享(Parameter Sharing): 由于卷积核是可以代表图片中的一类特征，比如水平或垂直边缘，因此复用性较强，可能图片左上和右下都是垂直边缘，用全连接描述可能参数就会重复，而用卷积核一个足矣。
2. 稀疏连接(Sparsity of Connnections)：卷积的运算结果只和整张图片的一小部分有关，不会像全连接那样把整张图片都展开进行计算。



<br>
## Part 6 残差网络 (Residual Networks ResNets)
使用残差网络可以让你训练超过100层的神经网络。我们通过一个例子来简单引出残差网络。

![输入图片说明](https://foruda.gitee.com/images/1662352969214126798/94d10651_5550632.png "屏幕截图")

上图为一个非常简单的神经网络结构。正常而言，我们只需要将上一层的激活函数结果传入下一层进行线性化然后调用激活函数进行非线性，一层一层向后传播即可。

对于残差网络，上图的那条蓝线我们称之为**Short cut/ Skip connection**

<br>

## Part 7 目标定位



<br>

## Part 8 序列模型:RNN，LSTM

<br>

## Part 9 总结

<br>

## Appendix-作业



